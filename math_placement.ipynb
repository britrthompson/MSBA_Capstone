{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier , plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.impute import SimpleImputer  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Read the math placement data from the Excel file\n",
    "df_math_placement = pd.read_excel('math_placement2024-02-29.xlsx')\n",
    "\n",
    "# Read the edready raw scores data from the CSV file\n",
    "df_ed_ready = pd.read_csv('edready_raw_scores.csv')\n",
    "\n",
    "# Load the file of incoming students\n",
    "#incoming_students = pd.read_csv('incoming_students.csv')will need to change to correct file name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PIDM</th>\n",
       "      <th>term_code</th>\n",
       "      <th>gid</th>\n",
       "      <th>admit_term</th>\n",
       "      <th>degree.x</th>\n",
       "      <th>major_code</th>\n",
       "      <th>college.x</th>\n",
       "      <th>major.x</th>\n",
       "      <th>stu_type</th>\n",
       "      <th>...</th>\n",
       "      <th>section_number</th>\n",
       "      <th>subj_code</th>\n",
       "      <th>section_type</th>\n",
       "      <th>credit_levl</th>\n",
       "      <th>course_credits</th>\n",
       "      <th>reg_status</th>\n",
       "      <th>grade</th>\n",
       "      <th>grade_category</th>\n",
       "      <th>course_level</th>\n",
       "      <th>PIDM_course_number_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>149852</td>\n",
       "      <td>202070</td>\n",
       "      <td>-110755</td>\n",
       "      <td>202070.0</td>\n",
       "      <td>Associate of Arts</td>\n",
       "      <td>AA</td>\n",
       "      <td>Gallatin College</td>\n",
       "      <td>Associate of Arts</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>922</td>\n",
       "      <td>M</td>\n",
       "      <td>L</td>\n",
       "      <td>UG</td>\n",
       "      <td>1</td>\n",
       "      <td>RE</td>\n",
       "      <td>A*</td>\n",
       "      <td>Successful</td>\n",
       "      <td>100.0</td>\n",
       "      <td>149852_063_202270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35</td>\n",
       "      <td>210982</td>\n",
       "      <td>202030</td>\n",
       "      <td>-171885</td>\n",
       "      <td>202030.0</td>\n",
       "      <td>Associate of Science</td>\n",
       "      <td>AS</td>\n",
       "      <td>Gallatin College</td>\n",
       "      <td>Associate of Science</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>STAT</td>\n",
       "      <td>L</td>\n",
       "      <td>UG</td>\n",
       "      <td>3</td>\n",
       "      <td>RW</td>\n",
       "      <td>B</td>\n",
       "      <td>Successful</td>\n",
       "      <td>300.0</td>\n",
       "      <td>210982_216Q_202170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>39</td>\n",
       "      <td>324739</td>\n",
       "      <td>202130</td>\n",
       "      <td>-1053980</td>\n",
       "      <td>202130.0</td>\n",
       "      <td>Associate of Arts</td>\n",
       "      <td>AA</td>\n",
       "      <td>Gallatin College</td>\n",
       "      <td>Associate of Arts</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>L</td>\n",
       "      <td>UG</td>\n",
       "      <td>3</td>\n",
       "      <td>RW</td>\n",
       "      <td>A</td>\n",
       "      <td>Successful</td>\n",
       "      <td>150.0</td>\n",
       "      <td>324739_105Q_202270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>43</td>\n",
       "      <td>372115</td>\n",
       "      <td>202170</td>\n",
       "      <td>-1097291</td>\n",
       "      <td>202170.0</td>\n",
       "      <td>Bachelor of Science</td>\n",
       "      <td>FNSC</td>\n",
       "      <td>College of Education/HHD</td>\n",
       "      <td>Food and Nutrition</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>M</td>\n",
       "      <td>L</td>\n",
       "      <td>UG</td>\n",
       "      <td>4</td>\n",
       "      <td>RW</td>\n",
       "      <td>A-</td>\n",
       "      <td>Successful</td>\n",
       "      <td>400.0</td>\n",
       "      <td>372115_161Q_202170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>47</td>\n",
       "      <td>376132</td>\n",
       "      <td>202170</td>\n",
       "      <td>-1100963</td>\n",
       "      <td>202170.0</td>\n",
       "      <td>Bachelor of Science</td>\n",
       "      <td>PBAC</td>\n",
       "      <td>College of Business</td>\n",
       "      <td>Pre-Business</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>L</td>\n",
       "      <td>UG</td>\n",
       "      <td>4</td>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "      <td>Unsuccessful</td>\n",
       "      <td>400.0</td>\n",
       "      <td>376132_161Q_202270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0    PIDM  term_code      gid  admit_term              degree.x  \\\n",
       "8           30  149852     202070  -110755    202070.0     Associate of Arts   \n",
       "9           35  210982     202030  -171885    202030.0  Associate of Science   \n",
       "11          39  324739     202130 -1053980    202130.0     Associate of Arts   \n",
       "13          43  372115     202170 -1097291    202170.0   Bachelor of Science   \n",
       "15          47  376132     202170 -1100963    202170.0   Bachelor of Science   \n",
       "\n",
       "   major_code                 college.x               major.x stu_type  ...  \\\n",
       "8          AA          Gallatin College     Associate of Arts        T  ...   \n",
       "9          AS          Gallatin College  Associate of Science        N  ...   \n",
       "11         AA          Gallatin College     Associate of Arts        T  ...   \n",
       "13       FNSC  College of Education/HHD    Food and Nutrition        T  ...   \n",
       "15       PBAC       College of Business          Pre-Business        T  ...   \n",
       "\n",
       "   section_number  subj_code  section_type  credit_levl  course_credits  \\\n",
       "8             922          M             L           UG               1   \n",
       "9               2       STAT             L           UG               3   \n",
       "11              2          M             L           UG               3   \n",
       "13              7          M             L           UG               4   \n",
       "15              2          M             L           UG               4   \n",
       "\n",
       "    reg_status  grade  grade_category  course_level  PIDM_course_number_term  \n",
       "8           RE     A*      Successful         100.0        149852_063_202270  \n",
       "9           RW      B      Successful         300.0       210982_216Q_202170  \n",
       "11          RW      A      Successful         150.0       324739_105Q_202270  \n",
       "13          RW     A-      Successful         400.0       372115_161Q_202170  \n",
       "15           W      W    Unsuccessful         400.0       376132_161Q_202270  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe to store the cleaned and imputed data\n",
    "df_cleaned = df_math_placement.copy()\n",
    "\n",
    "# Define the mapping of grades to grade categories\n",
    "grade_mapping = {\n",
    "    \"A\": \"Successful\", \n",
    "    \"B\": \"Successful\", \n",
    "    \"B+\": \"Successful\",\n",
    "    \"A-\": \"Successful\", \n",
    "    \"B*\": \"Successful\", \n",
    "    \"A*\": \"Successful\",\n",
    "    \"B+*\": \"Successful\", \n",
    "    \"W\": \"Unsuccessful\", \n",
    "    \"C-\": \"Unsuccessful\",\n",
    "    \"F\": \"Unsuccessful\", \n",
    "    \"B-\": \"Successful\", \n",
    "    \"C+\": \"Unsuccessful\",\n",
    "    \"D\": \"Unsuccessful\", \n",
    "    \"D*\": \"Unsuccessful\", \n",
    "    \"C\": \"Unsuccessful\",\n",
    "    \"W*\": \"Unsuccessful\", \n",
    "    \"P*\": \"Successful\", \n",
    "    \"C+*\": \"Unsuccessful\",\n",
    "    \"F*\": \"Unsuccessful\", \n",
    "    \"D+\": \"Unsuccessful\", \n",
    "    \"P\": \"Successful\",\n",
    "    \"C*\": \"Unsuccessful\", \n",
    "    \"A-*\": \"Successful\", \n",
    "    \"I\": \"Unsuccessful\",\n",
    "    \"AU\": \"Ignore\", \n",
    "    \"B-*\": \"Successful\",\n",
    "    \"D-\": \"Unsuccessful\",\n",
    "    \"NR\": \"Ignore\", \n",
    "    \"C-*\": \"Unsuccessful\", \n",
    "    \"I*\": \"Unsuccessful\",\n",
    "    \"NR*\": \"Ignore\"\n",
    "}\n",
    "\n",
    "# Map the grades to their categories and append as a new column\n",
    "df_cleaned['grade_category'] = df_cleaned['grade'].map(grade_mapping)\n",
    "\n",
    "\n",
    "# Define base courses and adjust the list based on 'campus_code'\n",
    "base_courses = ['088', '216Q', '132', '161Q', '151Q', '165Q', '171Q']\n",
    "courses_to_check = ['105Q', '090', '121Q']\n",
    "\n",
    "# Define a function to determine the course level based on the course number and campus code\n",
    "for course in courses_to_check:\n",
    "    if df_cleaned[(df_cleaned['campus_code'] != 'ZGC') & (df_cleaned['course_number'] == course)].shape[0] > 0:\n",
    "        base_courses.append(course)\n",
    "\n",
    "# Define course combinations\n",
    "course_combinations = {\n",
    "    'Combo1': ('005', '105Q'),\n",
    "    'Combo2': ('063', '090'),\n",
    "    'Combo3': ('021', '121Q')\n",
    "}\n",
    "\n",
    "# Map courses and combinations to levels\n",
    "course_levels = {\n",
    "    '088': 100,\n",
    "    'Combo2': 100,  # ('063', '090')\n",
    "    'Combo1': 150,  # ('005', '105Q')\n",
    "    '090': 150,\n",
    "    'Combo3': 250,  # ('021', '121Q')\n",
    "    '105Q': 290,\n",
    "    '216Q': 300,\n",
    "    '132': 300,\n",
    "    '121Q': 300,\n",
    "    '161Q': 400,\n",
    "    '151Q': 400,\n",
    "    '165Q': 500,\n",
    "    '171Q': 500\n",
    "}\n",
    "\n",
    "# Function to determine course level based on the course number or combination\n",
    "def determine_course_level(course_number, campus_code):\n",
    "    # Handle special cases for '105Q', '090', '121Q' based on 'campus_code'\n",
    "    if course_number in ['105Q', '090', '121Q'] and campus_code == 'ZGC':\n",
    "        # Exclude these courses for ZGC campus\n",
    "        return None\n",
    "    for combo_name, combo_courses in course_combinations.items():\n",
    "        if course_number in combo_courses:\n",
    "            # Return the level for the course combination\n",
    "            return course_levels[combo_name]\n",
    "    # Return the level for individual courses\n",
    "    return course_levels.get(course_number)\n",
    "\n",
    "# Apply the function to each row in df_cleaned to create a new 'course_level' column\n",
    "df_cleaned['course_level'] = df_cleaned.apply(lambda row: determine_course_level(row['course_number'], row['campus_code']), axis=1)\n",
    "\n",
    "\n",
    "# Removing the last 4 characters of each value in 'test_score' column\n",
    "df_cleaned['test_score'] = df_cleaned['test_score'].astype(str).str[:-4]\n",
    "\n",
    "# Make sure the column names match in both dataframes before merging\n",
    "df_cleaned.rename(columns={'pidm': 'PIDM'}, inplace=True)\n",
    "\n",
    "# Create a new column to store the PIDM, course number, and term as a single string\n",
    "df_cleaned['PIDM_course_number_term'] = df_cleaned['PIDM'].astype(str) + '_' + df_cleaned['course_number'].astype(str) + '_' + df_cleaned['term'].astype(str)\n",
    "\n",
    "# Remove duplicates based on the new column\n",
    "df_cleaned = df_cleaned.drop_duplicates(subset='PIDM_course_number_term')\n",
    "\n",
    "# Display the cleaned and imputed dataframe\n",
    "df_cleaned.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PIDM</th>\n",
       "      <th>term_code</th>\n",
       "      <th>gid</th>\n",
       "      <th>admit_term</th>\n",
       "      <th>degree.x</th>\n",
       "      <th>major_code</th>\n",
       "      <th>college.x</th>\n",
       "      <th>major.x</th>\n",
       "      <th>stu_type</th>\n",
       "      <th>...</th>\n",
       "      <th>section_number</th>\n",
       "      <th>subj_code</th>\n",
       "      <th>section_type</th>\n",
       "      <th>credit_levl</th>\n",
       "      <th>course_credits</th>\n",
       "      <th>reg_status</th>\n",
       "      <th>grade</th>\n",
       "      <th>grade_category</th>\n",
       "      <th>course_level</th>\n",
       "      <th>PIDM_course_number_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>149852</td>\n",
       "      <td>202070</td>\n",
       "      <td>-110755</td>\n",
       "      <td>202070.0</td>\n",
       "      <td>Associate of Arts</td>\n",
       "      <td>AA</td>\n",
       "      <td>Gallatin College</td>\n",
       "      <td>Associate of Arts</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>922</td>\n",
       "      <td>M</td>\n",
       "      <td>L</td>\n",
       "      <td>UG</td>\n",
       "      <td>1</td>\n",
       "      <td>RE</td>\n",
       "      <td>A*</td>\n",
       "      <td>Successful</td>\n",
       "      <td>100.0</td>\n",
       "      <td>149852_063_202270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>210982</td>\n",
       "      <td>202030</td>\n",
       "      <td>-171885</td>\n",
       "      <td>202030.0</td>\n",
       "      <td>Associate of Science</td>\n",
       "      <td>AS</td>\n",
       "      <td>Gallatin College</td>\n",
       "      <td>Associate of Science</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>STAT</td>\n",
       "      <td>L</td>\n",
       "      <td>UG</td>\n",
       "      <td>3</td>\n",
       "      <td>RW</td>\n",
       "      <td>B</td>\n",
       "      <td>Successful</td>\n",
       "      <td>300.0</td>\n",
       "      <td>210982_216Q_202170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>324739</td>\n",
       "      <td>202130</td>\n",
       "      <td>-1053980</td>\n",
       "      <td>202130.0</td>\n",
       "      <td>Associate of Arts</td>\n",
       "      <td>AA</td>\n",
       "      <td>Gallatin College</td>\n",
       "      <td>Associate of Arts</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>L</td>\n",
       "      <td>UG</td>\n",
       "      <td>3</td>\n",
       "      <td>RW</td>\n",
       "      <td>A</td>\n",
       "      <td>Successful</td>\n",
       "      <td>150.0</td>\n",
       "      <td>324739_105Q_202270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>372115</td>\n",
       "      <td>202170</td>\n",
       "      <td>-1097291</td>\n",
       "      <td>202170.0</td>\n",
       "      <td>Bachelor of Science</td>\n",
       "      <td>FNSC</td>\n",
       "      <td>College of Education/HHD</td>\n",
       "      <td>Food and Nutrition</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>M</td>\n",
       "      <td>L</td>\n",
       "      <td>UG</td>\n",
       "      <td>4</td>\n",
       "      <td>RW</td>\n",
       "      <td>A-</td>\n",
       "      <td>Successful</td>\n",
       "      <td>400.0</td>\n",
       "      <td>372115_161Q_202170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>376132</td>\n",
       "      <td>202170</td>\n",
       "      <td>-1100963</td>\n",
       "      <td>202170.0</td>\n",
       "      <td>Bachelor of Science</td>\n",
       "      <td>PBAC</td>\n",
       "      <td>College of Business</td>\n",
       "      <td>Pre-Business</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>921</td>\n",
       "      <td>M</td>\n",
       "      <td>L</td>\n",
       "      <td>UG</td>\n",
       "      <td>2</td>\n",
       "      <td>RW</td>\n",
       "      <td>A*</td>\n",
       "      <td>Successful</td>\n",
       "      <td>100.0</td>\n",
       "      <td>376132_063_202230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    PIDM  term_code      gid  admit_term              degree.x  \\\n",
       "0          30  149852     202070  -110755    202070.0     Associate of Arts   \n",
       "1          35  210982     202030  -171885    202030.0  Associate of Science   \n",
       "2          39  324739     202130 -1053980    202130.0     Associate of Arts   \n",
       "3          43  372115     202170 -1097291    202170.0   Bachelor of Science   \n",
       "4          49  376132     202170 -1100963    202170.0   Bachelor of Science   \n",
       "\n",
       "  major_code                 college.x               major.x stu_type  ...  \\\n",
       "0         AA          Gallatin College     Associate of Arts        T  ...   \n",
       "1         AS          Gallatin College  Associate of Science        N  ...   \n",
       "2         AA          Gallatin College     Associate of Arts        T  ...   \n",
       "3       FNSC  College of Education/HHD    Food and Nutrition        T  ...   \n",
       "4       PBAC       College of Business          Pre-Business        T  ...   \n",
       "\n",
       "  section_number  subj_code  section_type  credit_levl  course_credits  \\\n",
       "0            922          M             L           UG               1   \n",
       "1              2       STAT             L           UG               3   \n",
       "2              2          M             L           UG               3   \n",
       "3              7          M             L           UG               4   \n",
       "4            921          M             L           UG               2   \n",
       "\n",
       "   reg_status  grade  grade_category  course_level  PIDM_course_number_term  \n",
       "0          RE     A*      Successful         100.0        149852_063_202270  \n",
       "1          RW      B      Successful         300.0       210982_216Q_202170  \n",
       "2          RW      A      Successful         150.0       324739_105Q_202270  \n",
       "3          RW     A-      Successful         400.0       372115_161Q_202170  \n",
       "4          RW     A*      Successful         100.0        376132_063_202230  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Convert 'term' to a numeric type to ensure correct sorting\n",
    "df_cleaned['term'] = pd.to_numeric(df_cleaned['term'])\n",
    "\n",
    "# Find the oldest term for each PIDM\n",
    "oldest_terms = df_cleaned.groupby('PIDM')['term'].min().reset_index()\n",
    "\n",
    "# Merge the oldest terms back to the original DataFrame to filter records\n",
    "df_oldest = pd.merge(df_cleaned, oldest_terms, on=['PIDM', 'term'], how='inner')\n",
    "\n",
    "# Now, df_oldest contains only the records of the oldest term for each PIDM,\n",
    "# including cases where there are multiple records for a PIDM within that oldest term\n",
    "\n",
    "# Sort PIDM\n",
    "df_oldest.sort_values(by=['PIDM', 'term'], ascending=[True, True], inplace=True)\n",
    "\n",
    "# Show the updated DataFrame\n",
    "df_oldest.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PIDM</th>\n",
       "      <th>term_code</th>\n",
       "      <th>gid</th>\n",
       "      <th>admit_term</th>\n",
       "      <th>degree.x</th>\n",
       "      <th>major_code</th>\n",
       "      <th>college.x</th>\n",
       "      <th>major.x</th>\n",
       "      <th>stu_type</th>\n",
       "      <th>...</th>\n",
       "      <th>subj_code</th>\n",
       "      <th>section_type</th>\n",
       "      <th>credit_levl</th>\n",
       "      <th>course_credits</th>\n",
       "      <th>reg_status</th>\n",
       "      <th>grade</th>\n",
       "      <th>grade_category</th>\n",
       "      <th>course_level</th>\n",
       "      <th>PIDM_course_number_term</th>\n",
       "      <th>ERM_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>149852</td>\n",
       "      <td>202070</td>\n",
       "      <td>-110755</td>\n",
       "      <td>202070.0</td>\n",
       "      <td>Associate of Arts</td>\n",
       "      <td>AA</td>\n",
       "      <td>Gallatin College</td>\n",
       "      <td>Associate of Arts</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>L</td>\n",
       "      <td>UG</td>\n",
       "      <td>1</td>\n",
       "      <td>RE</td>\n",
       "      <td>A*</td>\n",
       "      <td>Successful</td>\n",
       "      <td>100.0</td>\n",
       "      <td>149852_063_202270</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>210982</td>\n",
       "      <td>202030</td>\n",
       "      <td>-171885</td>\n",
       "      <td>202030.0</td>\n",
       "      <td>Associate of Science</td>\n",
       "      <td>AS</td>\n",
       "      <td>Gallatin College</td>\n",
       "      <td>Associate of Science</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>STAT</td>\n",
       "      <td>L</td>\n",
       "      <td>UG</td>\n",
       "      <td>3</td>\n",
       "      <td>RW</td>\n",
       "      <td>B</td>\n",
       "      <td>Successful</td>\n",
       "      <td>300.0</td>\n",
       "      <td>210982_216Q_202170</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>324739</td>\n",
       "      <td>202130</td>\n",
       "      <td>-1053980</td>\n",
       "      <td>202130.0</td>\n",
       "      <td>Associate of Arts</td>\n",
       "      <td>AA</td>\n",
       "      <td>Gallatin College</td>\n",
       "      <td>Associate of Arts</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>L</td>\n",
       "      <td>UG</td>\n",
       "      <td>3</td>\n",
       "      <td>RW</td>\n",
       "      <td>A</td>\n",
       "      <td>Successful</td>\n",
       "      <td>150.0</td>\n",
       "      <td>324739_105Q_202270</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>372115</td>\n",
       "      <td>202170</td>\n",
       "      <td>-1097291</td>\n",
       "      <td>202170.0</td>\n",
       "      <td>Bachelor of Science</td>\n",
       "      <td>FNSC</td>\n",
       "      <td>College of Education/HHD</td>\n",
       "      <td>Food and Nutrition</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>L</td>\n",
       "      <td>UG</td>\n",
       "      <td>4</td>\n",
       "      <td>RW</td>\n",
       "      <td>A-</td>\n",
       "      <td>Successful</td>\n",
       "      <td>400.0</td>\n",
       "      <td>372115_161Q_202170</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>376132</td>\n",
       "      <td>202170</td>\n",
       "      <td>-1100963</td>\n",
       "      <td>202170.0</td>\n",
       "      <td>Bachelor of Science</td>\n",
       "      <td>PBAC</td>\n",
       "      <td>College of Business</td>\n",
       "      <td>Pre-Business</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>L</td>\n",
       "      <td>UG</td>\n",
       "      <td>2</td>\n",
       "      <td>RW</td>\n",
       "      <td>A*</td>\n",
       "      <td>Successful</td>\n",
       "      <td>100.0</td>\n",
       "      <td>376132_063_202230</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    PIDM  term_code      gid  admit_term              degree.x  \\\n",
       "0          30  149852     202070  -110755    202070.0     Associate of Arts   \n",
       "1          35  210982     202030  -171885    202030.0  Associate of Science   \n",
       "2          39  324739     202130 -1053980    202130.0     Associate of Arts   \n",
       "3          43  372115     202170 -1097291    202170.0   Bachelor of Science   \n",
       "4          49  376132     202170 -1100963    202170.0   Bachelor of Science   \n",
       "\n",
       "  major_code                 college.x               major.x stu_type  ...  \\\n",
       "0         AA          Gallatin College     Associate of Arts        T  ...   \n",
       "1         AS          Gallatin College  Associate of Science        N  ...   \n",
       "2         AA          Gallatin College     Associate of Arts        T  ...   \n",
       "3       FNSC  College of Education/HHD    Food and Nutrition        T  ...   \n",
       "4       PBAC       College of Business          Pre-Business        T  ...   \n",
       "\n",
       "  subj_code  section_type  credit_levl  course_credits  reg_status  grade  \\\n",
       "0         M             L           UG               1          RE     A*   \n",
       "1      STAT             L           UG               3          RW      B   \n",
       "2         M             L           UG               3          RW      A   \n",
       "3         M             L           UG               4          RW     A-   \n",
       "4         M             L           UG               2          RW     A*   \n",
       "\n",
       "   grade_category  course_level  PIDM_course_number_term  ERM_SCORE  \n",
       "0      Successful         100.0        149852_063_202270       10.0  \n",
       "1      Successful         300.0       210982_216Q_202170        NaN  \n",
       "2      Successful         150.0       324739_105Q_202270       30.0  \n",
       "3      Successful         400.0       372115_161Q_202170       40.0  \n",
       "4      Successful         100.0        376132_063_202230       10.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trim whitespace from headers\n",
    "df_oldest.columns = df_oldest.columns.str.strip()\n",
    "df_ed_ready.columns = df_ed_ready.columns.str.strip()\n",
    "\n",
    "# Merge the two dataframes based on the PIDM\n",
    "df_merged = pd.merge(df_oldest, df_ed_ready[['PIDM', 'ERM_SCORE']], on='PIDM', how='left')\n",
    "\n",
    "# Display the merged dataframe\n",
    "df_merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      test_score  ERM_SCORE  sat_new_math  act_math  hs_gpa   Compliance\n",
      "0            100       10.0           NaN       NaN    1.72  Uncompliant\n",
      "1            100        NaN           NaN       NaN    2.50    Compliant\n",
      "2            300       30.0           NaN       NaN     NaN  Uncompliant\n",
      "3            400       40.0           NaN       NaN     NaN  Uncompliant\n",
      "4            100       10.0           NaN       NaN     NaN  Uncompliant\n",
      "...          ...        ...           ...       ...     ...          ...\n",
      "12353        300       30.0           NaN       NaN     NaN  Uncompliant\n",
      "12354        300       30.0           NaN       NaN     NaN  Uncompliant\n",
      "12355        400       40.0           NaN       NaN     NaN  Uncompliant\n",
      "12356        300       30.0           NaN       NaN    3.00  Uncompliant\n",
      "12357        250        NaN           NaN      20.0    4.30    Compliant\n",
      "\n",
      "[12358 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define thresholds for single scores\n",
    "erm_score_thresholds = {\n",
    "    100: 10,\n",
    "    150: 15,\n",
    "    250: 25,\n",
    "    290: 30,\n",
    "    300: 30,\n",
    "    400: 40,\n",
    "    500: 50,\n",
    "}\n",
    "\n",
    "# Define thresholds for SAT and ACT as tuples (min, max)\n",
    "sat_new_math_thresholds = {\n",
    "    100: (None, 460),\n",
    "    150: (460, 529),\n",
    "    250: (530, 539),\n",
    "    290: (540, 559),\n",
    "    300: (560, 589),\n",
    "    400: (590, 639),\n",
    "    500: (640, 640),\n",
    "}\n",
    "act_math_thresholds = {\n",
    "    100: (None, 17),\n",
    "    150: (17, 20),\n",
    "    250: (21, 21),\n",
    "    290: (22, 22),\n",
    "    300: (23, 24),\n",
    "    400: (25, 26),\n",
    "    500: (27, 27),\n",
    "}\n",
    "\n",
    "# Define dual thresholds for SAT new math and high school GPA\n",
    "dual_sat_gpa_thresholds = {\n",
    "    150: (380, 519, None, 3.0),\n",
    "    250: (520, 529, 3.01, 3.5),\n",
    "    290: (530, 530, 3.01, 3.5),\n",
    "    300: (530, 559, 3.01, 3.5),\n",
    "    400: (560, 580, 3.7, 4.5),\n",
    "}\n",
    "\n",
    "# Define dual thresholds for ACT math and high school GPA\n",
    "dual_act_gpa_thresholds = {\n",
    "    150: (15, 19, None, 3.0),\n",
    "    250: (20, 20, 3.01, 3.5),\n",
    "    290: (21, 21, 3.01, 3.5),\n",
    "    300: (21, 22, 3.01, 3.5),\n",
    "    400: (23, 24, 3.7, 4.5),\n",
    "}\n",
    "# The compliance checking function\n",
    "def check_compliance(row):\n",
    "    level = row['test_score']\n",
    "    erm_score = row.get('ERM_SCORE', 0)\n",
    "    sat_score = row.get('sat_new_math', 0)\n",
    "    act_score = row.get('act_math', 0)\n",
    "    gpa = row.get('hs_gpa', 0)\n",
    "    \n",
    "    # Check ERM compliance\n",
    "    if erm_score < erm_score_thresholds.get(level, float('inf')):\n",
    "        return 'Uncompliant'\n",
    "    \n",
    "    # SAT score compliance\n",
    "    sat_range = sat_new_math_thresholds.get(level, (None, None))\n",
    "    if sat_score < (sat_range[0] if sat_range[0] is not None else float('-inf')) or \\\n",
    "       sat_score > (sat_range[1] if sat_range[1] is not None else float('inf')):\n",
    "        return 'Uncompliant'\n",
    "    \n",
    "    # ACT score compliance\n",
    "    act_range = act_math_thresholds.get(level, (None, None))\n",
    "    if act_score < (act_range[0] if act_range[0] is not None else float('-inf')) or \\\n",
    "       act_score > (act_range[1] if act_range[1] is not None else float('inf')):\n",
    "        return 'Uncompliant'\n",
    "    \n",
    "    # Dual score compliance checks need to handle GPA and SAT/ACT together\n",
    "    sat_gpa_range = dual_sat_gpa_thresholds.get(level, (None, None, None, None))\n",
    "    act_gpa_range = dual_act_gpa_thresholds.get(level, (None, None, None, None))\n",
    "\n",
    "    # SAT & GPA compliance\n",
    "    if (sat_gpa_range[0] is None or sat_score >= sat_gpa_range[0]) and \\\n",
    "       (sat_gpa_range[1] is None or sat_score <= sat_gpa_range[1]) and \\\n",
    "       (sat_gpa_range[2] is None or gpa >= sat_gpa_range[2]) and \\\n",
    "       (sat_gpa_range[3] is None or gpa <= sat_gpa_range[3]):\n",
    "        return 'Compliant'\n",
    "\n",
    "    # ACT & GPA compliance\n",
    "    if (act_gpa_range[0] is None or act_score >= act_gpa_range[0]) and \\\n",
    "       (act_gpa_range[1] is None or act_score <= act_gpa_range[1]) and \\\n",
    "       (act_gpa_range[2] is None or gpa >= act_gpa_range[2]) and \\\n",
    "       (act_gpa_range[3] is None or gpa <= act_gpa_range[3]):\n",
    "        return 'Compliant'\n",
    "    \n",
    "    return 'Uncompliant'\n",
    "\n",
    "# Apply the compliance checking function to each row of the DataFrame\n",
    "df_merged['Compliance'] = df_merged.apply(check_compliance, axis=1)\n",
    "\n",
    "\n",
    "# Output the DataFrame to check the compliance results\n",
    "print(df_merged[['test_score', 'ERM_SCORE', 'sat_new_math', 'act_math', 'hs_gpa', 'Compliance']])\n",
    "\n",
    "\n",
    "df_merged = df_merged[df_merged['Compliance'] == 'Compliant']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df_merged: 7359\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows in the merged dataframe\n",
    "num_rows = df_merged.shape[0]\n",
    "print(f\"Number of rows in df_merged: {num_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grade_category\n",
      "Successful      4512\n",
      "Unsuccessful    2811\n",
      "Ignore            25\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Count the occurrences of each grade category\n",
    "grade_counts = df_merged['grade_category'].value_counts()\n",
    "\n",
    "# Display the count of each grade category\n",
    "print(grade_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grade_category  Ignore  Successful  Unsuccessful  successful_ratio\n",
      "test_score                                                        \n",
      "                    15         302           252          0.530756\n",
      "100                  1         140           177          0.440252\n",
      "150                  5         612           640          0.486874\n",
      "250                  0         201           142          0.586006\n",
      "290                  0         111           108          0.506849\n",
      "300                  3         723           585          0.551487\n",
      "400                  1         997           497          0.666890\n",
      "450                  0         185            35          0.840909\n",
      "500                  0        1241           375          0.767946\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Group by 'course_level' and then count occurrences of each 'grade_category' within each level\n",
    "grade_category_distribution = df_merged.groupby('test_score')['grade_category'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "\n",
    "# Add a new column to store the ratio of successful students\n",
    "grade_category_distribution['successful_ratio'] = grade_category_distribution['Successful'] / (grade_category_distribution['Ignore'] + grade_category_distribution['Successful'] + grade_category_distribution['Unsuccessful'])\n",
    "\n",
    "\n",
    "# Display the distribution of grade categories within each course level\n",
    "print(grade_category_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grade_category  Ignore  Successful  Unsuccessful  successful_ratio\n",
      "course_number                                                     \n",
      "088                  0          31            27          0.534483\n",
      "216Q                 0        1049           696          0.601146\n",
      "132                  0          80            22          0.784314\n",
      "161Q                 0         842           474          0.639818\n",
      "151Q                 0         417           244          0.630862\n",
      "165Q                 0          43            33          0.565789\n",
      "171Q                 0         584           357          0.620616\n",
      "105Q                14         219            99          0.659639\n",
      "090                  0          31            39          0.442857\n",
      "121Q                11         479           419          0.526953\n",
      "105Q                14         219            99          0.659639\n",
      "090                  0          31            39          0.442857\n",
      "121Q                11         479           419          0.526953\n"
     ]
    }
   ],
   "source": [
    "# Group by 'course_level' and then count occurrences of each 'grade_category' within each level\n",
    "grade_category_distribution = df_merged.groupby('course_number')['grade_category'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "grade_category_distribution['successful_ratio'] = grade_category_distribution['Successful'] / (grade_category_distribution['Ignore'] + grade_category_distribution['Successful'] + grade_category_distribution['Unsuccessful'])\n",
    "\n",
    "\n",
    "# Display the distribution of grade categories within each course level\n",
    "# Filter the grade_category_distribution for base courses and combos\n",
    "filtered_distribution = grade_category_distribution.loc[base_courses + courses_to_check]\n",
    "\n",
    "# Print the filtered grade_category_distribution\n",
    "print(filtered_distribution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hs_gpa</th>\n",
       "      <th>act_math</th>\n",
       "      <th>sat_new_math</th>\n",
       "      <th>ERM_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6524.000000</td>\n",
       "      <td>4443.000000</td>\n",
       "      <td>2559.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.512922</td>\n",
       "      <td>23.204366</td>\n",
       "      <td>583.442751</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498882</td>\n",
       "      <td>4.566395</td>\n",
       "      <td>73.820592</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.210000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.650000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.940000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.730000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hs_gpa     act_math  sat_new_math  ERM_SCORE\n",
       "count  6524.000000  4443.000000   2559.000000        0.0\n",
       "mean      3.512922    23.204366    583.442751        NaN\n",
       "std       0.498882     4.566395     73.820592        NaN\n",
       "min       0.000000    12.000000    310.000000        NaN\n",
       "25%       3.210000    20.000000    540.000000        NaN\n",
       "50%       3.650000    24.000000    580.000000        NaN\n",
       "75%       3.940000    26.000000    630.000000        NaN\n",
       "max       4.730000    36.000000    800.000000        NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[['hs_gpa','act_math','sat_new_math', 'ERM_SCORE', 'test_score', 'grade_category']].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Logistic Regression Model - Course Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 088 with variables ['ERM_SCORE'] due to NaN values.\n",
      "Skipping 088 with variables ['hs_gpa', 'ERM_SCORE'] due to NaN values.\n",
      "Error fitting model for 088 with variables ['sat_new_math']: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1\n",
      "Course Level: 088, Variables: ['act_math']\n",
      "Accuracy: 0.50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.56      0.83      0.67         6\n",
      "Unsuccessful       0.00      0.00      1.00         4\n",
      "\n",
      "    accuracy                           0.50        10\n",
      "   macro avg       0.28      0.42      0.83        10\n",
      "weighted avg       0.33      0.50      0.80        10\n",
      "\n",
      "--------------------\n",
      "\n",
      "Error fitting model for 088 with variables ['hs_gpa', 'sat_new_math']: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1\n",
      "Course Level: 088, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       1.00      0.75      0.86         4\n",
      "Unsuccessful       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.92      0.88      0.88         9\n",
      "weighted avg       0.91      0.89      0.89         9\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping 216Q with variables ['ERM_SCORE'] due to NaN values.\n",
      "Skipping 216Q with variables ['hs_gpa', 'ERM_SCORE'] due to NaN values.\n",
      "Course Level: 216Q, Variables: ['sat_new_math']\n",
      "Accuracy: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.71      0.99      0.83        80\n",
      "Unsuccessful       0.93      0.29      0.44        45\n",
      "\n",
      "    accuracy                           0.74       125\n",
      "   macro avg       0.82      0.64      0.63       125\n",
      "weighted avg       0.79      0.74      0.69       125\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 216Q, Variables: ['act_math']\n",
      "Accuracy: 0.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.63      0.91      0.75       118\n",
      "Unsuccessful       0.74      0.33      0.46        93\n",
      "\n",
      "    accuracy                           0.65       211\n",
      "   macro avg       0.69      0.62      0.60       211\n",
      "weighted avg       0.68      0.65      0.62       211\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 216Q, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.80      0.89      0.84        84\n",
      "Unsuccessful       0.61      0.42      0.50        33\n",
      "\n",
      "    accuracy                           0.76       117\n",
      "   macro avg       0.70      0.66      0.67       117\n",
      "weighted avg       0.74      0.76      0.75       117\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 216Q, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.73      0.84      0.78       117\n",
      "Unsuccessful       0.68      0.53      0.59        76\n",
      "\n",
      "    accuracy                           0.72       193\n",
      "   macro avg       0.70      0.68      0.69       193\n",
      "weighted avg       0.71      0.72      0.71       193\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping 132 with variables ['ERM_SCORE'] due to NaN values.\n",
      "Skipping 132 with variables ['hs_gpa', 'ERM_SCORE'] due to NaN values.\n",
      "Course Level: 132, Variables: ['sat_new_math']\n",
      "Accuracy: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 132, Variables: ['act_math']\n",
      "Accuracy: 0.59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.59      1.00      0.74        10\n",
      "Unsuccessful       1.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.59        17\n",
      "   macro avg       0.79      0.50      0.37        17\n",
      "weighted avg       0.76      0.59      0.44        17\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 132, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 132, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.86      1.00      0.92        12\n",
      "Unsuccessful       1.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.93      0.50      0.46        14\n",
      "weighted avg       0.88      0.86      0.79        14\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping 161Q with variables ['ERM_SCORE'] due to NaN values.\n",
      "Skipping 161Q with variables ['hs_gpa', 'ERM_SCORE'] due to NaN values.\n",
      "Course Level: 161Q, Variables: ['sat_new_math']\n",
      "Accuracy: 0.60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.61      0.89      0.72        54\n",
      "Unsuccessful       0.54      0.18      0.27        38\n",
      "\n",
      "    accuracy                           0.60        92\n",
      "   macro avg       0.57      0.54      0.50        92\n",
      "weighted avg       0.58      0.60      0.54        92\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 161Q, Variables: ['act_math']\n",
      "Accuracy: 0.76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.79      0.87      0.83       101\n",
      "Unsuccessful       0.68      0.54      0.60        52\n",
      "\n",
      "    accuracy                           0.76       153\n",
      "   macro avg       0.73      0.70      0.71       153\n",
      "weighted avg       0.75      0.76      0.75       153\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 161Q, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.76      0.88      0.81        57\n",
      "Unsuccessful       0.67      0.47      0.55        30\n",
      "\n",
      "    accuracy                           0.74        87\n",
      "   macro avg       0.71      0.67      0.68        87\n",
      "weighted avg       0.73      0.74      0.72        87\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 161Q, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.80      0.87      0.83        91\n",
      "Unsuccessful       0.71      0.60      0.65        50\n",
      "\n",
      "    accuracy                           0.77       141\n",
      "   macro avg       0.76      0.73      0.74       141\n",
      "weighted avg       0.77      0.77      0.77       141\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping 151Q with variables ['ERM_SCORE'] due to NaN values.\n",
      "Skipping 151Q with variables ['hs_gpa', 'ERM_SCORE'] due to NaN values.\n",
      "Course Level: 151Q, Variables: ['sat_new_math']\n",
      "Accuracy: 0.58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.58      0.97      0.73        29\n",
      "Unsuccessful       0.50      0.05      0.09        21\n",
      "\n",
      "    accuracy                           0.58        50\n",
      "   macro avg       0.54      0.51      0.41        50\n",
      "weighted avg       0.55      0.58      0.46        50\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 151Q, Variables: ['act_math']\n",
      "Accuracy: 0.58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.61      0.92      0.73        48\n",
      "Unsuccessful       0.20      0.03      0.06        29\n",
      "\n",
      "    accuracy                           0.58        77\n",
      "   macro avg       0.41      0.48      0.40        77\n",
      "weighted avg       0.46      0.58      0.48        77\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 151Q, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.76      0.84      0.80        31\n",
      "Unsuccessful       0.64      0.53      0.58        17\n",
      "\n",
      "    accuracy                           0.73        48\n",
      "   macro avg       0.70      0.68      0.69        48\n",
      "weighted avg       0.72      0.73      0.72        48\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 151Q, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.78      0.87      0.82        53\n",
      "Unsuccessful       0.50      0.35      0.41        20\n",
      "\n",
      "    accuracy                           0.73        73\n",
      "   macro avg       0.64      0.61      0.62        73\n",
      "weighted avg       0.70      0.73      0.71        73\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping 165Q with variables ['ERM_SCORE'] due to NaN values.\n",
      "Skipping 165Q with variables ['hs_gpa', 'ERM_SCORE'] due to NaN values.\n",
      "Course Level: 165Q, Variables: ['sat_new_math']\n",
      "Accuracy: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       1.00      0.67      0.80         3\n",
      "Unsuccessful       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.80         5\n",
      "   macro avg       0.83      0.83      0.80         5\n",
      "weighted avg       0.87      0.80      0.80         5\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 165Q, Variables: ['act_math']\n",
      "Accuracy: 0.50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.44      1.00      0.62         4\n",
      "Unsuccessful       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.50        10\n",
      "   macro avg       0.72      0.58      0.45        10\n",
      "weighted avg       0.78      0.50      0.42        10\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 165Q, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       1.00      0.33      0.50         3\n",
      "Unsuccessful       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.75      0.67      0.58         5\n",
      "weighted avg       0.80      0.60      0.57         5\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 165Q, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.57      0.80      0.67         5\n",
      "Unsuccessful       0.50      0.25      0.33         4\n",
      "\n",
      "    accuracy                           0.56         9\n",
      "   macro avg       0.54      0.53      0.50         9\n",
      "weighted avg       0.54      0.56      0.52         9\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping 171Q with variables ['ERM_SCORE'] due to NaN values.\n",
      "Skipping 171Q with variables ['hs_gpa', 'ERM_SCORE'] due to NaN values.\n",
      "Course Level: 171Q, Variables: ['sat_new_math']\n",
      "Accuracy: 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.79      0.96      0.87        54\n",
      "Unsuccessful       0.75      0.30      0.43        20\n",
      "\n",
      "    accuracy                           0.78        74\n",
      "   macro avg       0.77      0.63      0.65        74\n",
      "weighted avg       0.78      0.78      0.75        74\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 171Q, Variables: ['act_math']\n",
      "Accuracy: 0.70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.75      0.87      0.81        79\n",
      "Unsuccessful       0.47      0.28      0.35        32\n",
      "\n",
      "    accuracy                           0.70       111\n",
      "   macro avg       0.61      0.58      0.58       111\n",
      "weighted avg       0.67      0.70      0.68       111\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 171Q, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.68      0.91      0.78        43\n",
      "Unsuccessful       0.71      0.36      0.48        28\n",
      "\n",
      "    accuracy                           0.69        71\n",
      "   macro avg       0.70      0.63      0.63        71\n",
      "weighted avg       0.70      0.69      0.66        71\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 171Q, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.69      0.92      0.79        60\n",
      "Unsuccessful       0.78      0.42      0.55        43\n",
      "\n",
      "    accuracy                           0.71       103\n",
      "   macro avg       0.74      0.67      0.67       103\n",
      "weighted avg       0.73      0.71      0.69       103\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping 105Q with variables ['ERM_SCORE'] due to NaN values.\n",
      "Skipping 105Q with variables ['hs_gpa', 'ERM_SCORE'] due to NaN values.\n",
      "Course Level: 105Q, Variables: ['sat_new_math']\n",
      "Accuracy: 0.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.68      1.00      0.81        13\n",
      "Unsuccessful       1.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.68        19\n",
      "   macro avg       0.84      0.50      0.41        19\n",
      "weighted avg       0.78      0.68      0.56        19\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 105Q, Variables: ['act_math']\n",
      "Accuracy: 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Ignore       1.00      0.00      0.00         2\n",
      "  Successful       0.70      0.96      0.81        27\n",
      "Unsuccessful       0.75      0.25      0.38        12\n",
      "\n",
      "    accuracy                           0.71        41\n",
      "   macro avg       0.82      0.40      0.40        41\n",
      "weighted avg       0.73      0.71      0.64        41\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 105Q, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.87      0.93      0.90        14\n",
      "Unsuccessful       0.67      0.50      0.57         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.77      0.71      0.73        18\n",
      "weighted avg       0.82      0.83      0.82        18\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 105Q, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.84      0.91      0.87        23\n",
      "Unsuccessful       0.82      0.69      0.75        13\n",
      "\n",
      "    accuracy                           0.83        36\n",
      "   macro avg       0.83      0.80      0.81        36\n",
      "weighted avg       0.83      0.83      0.83        36\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping 090 with variables ['ERM_SCORE'] due to NaN values.\n",
      "Skipping 090 with variables ['hs_gpa', 'ERM_SCORE'] due to NaN values.\n",
      "Course Level: 090, Variables: ['sat_new_math']\n",
      "Accuracy: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Unsuccessful       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 090, Variables: ['act_math']\n",
      "Accuracy: 0.70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       1.00      0.00      0.00         3\n",
      "Unsuccessful       0.70      1.00      0.82         7\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.85      0.50      0.41        10\n",
      "weighted avg       0.79      0.70      0.58        10\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 090, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       1.00      0.00      0.00         1\n",
      "Unsuccessful       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.88      0.50      0.43         4\n",
      "weighted avg       0.81      0.75      0.64         4\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 090, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.50      0.25      0.33         4\n",
      "Unsuccessful       0.57      0.80      0.67         5\n",
      "\n",
      "    accuracy                           0.56         9\n",
      "   macro avg       0.54      0.53      0.50         9\n",
      "weighted avg       0.54      0.56      0.52         9\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping 121Q with variables ['ERM_SCORE'] due to NaN values.\n",
      "Skipping 121Q with variables ['hs_gpa', 'ERM_SCORE'] due to NaN values.\n",
      "Course Level: 121Q, Variables: ['sat_new_math']\n",
      "Accuracy: 0.46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.46      1.00      0.63        32\n",
      "Unsuccessful       1.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.46        70\n",
      "   macro avg       0.73      0.50      0.31        70\n",
      "weighted avg       0.75      0.46      0.29        70\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 121Q, Variables: ['act_math']\n",
      "Accuracy: 0.62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.63      0.81      0.71        62\n",
      "Unsuccessful       0.60      0.38      0.47        47\n",
      "\n",
      "    accuracy                           0.62       109\n",
      "   macro avg       0.62      0.59      0.59       109\n",
      "weighted avg       0.62      0.62      0.61       109\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 121Q, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.71      0.73      0.72        33\n",
      "Unsuccessful       0.72      0.70      0.71        33\n",
      "\n",
      "    accuracy                           0.71        66\n",
      "   macro avg       0.71      0.71      0.71        66\n",
      "weighted avg       0.71      0.71      0.71        66\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 121Q, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.62      0.84      0.71        50\n",
      "Unsuccessful       0.74      0.47      0.58        49\n",
      "\n",
      "    accuracy                           0.66        99\n",
      "   macro avg       0.68      0.65      0.64        99\n",
      "weighted avg       0.68      0.66      0.64        99\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping Combo1 with variables ['ERM_SCORE'] due to NaN values.\n",
      "Skipping Combo1 with variables ['hs_gpa', 'ERM_SCORE'] due to NaN values.\n",
      "Course Level: Combo1, Variables: ['sat_new_math']\n",
      "Accuracy: 0.67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.71      0.92      0.80        24\n",
      "Unsuccessful       0.00      0.00      1.00         9\n",
      "\n",
      "    accuracy                           0.67        33\n",
      "   macro avg       0.35      0.46      0.90        33\n",
      "weighted avg       0.52      0.67      0.85        33\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: Combo1, Variables: ['act_math']\n",
      "Accuracy: 0.61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Ignore       1.00      0.00      0.00         2\n",
      "  Successful       0.59      0.98      0.74        42\n",
      "Unsuccessful       0.83      0.16      0.27        31\n",
      "\n",
      "    accuracy                           0.61        75\n",
      "   macro avg       0.81      0.38      0.34        75\n",
      "weighted avg       0.70      0.61      0.53        75\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: Combo1, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.72      0.90      0.80        20\n",
      "Unsuccessful       0.67      0.36      0.47        11\n",
      "\n",
      "    accuracy                           0.71        31\n",
      "   macro avg       0.69      0.63      0.64        31\n",
      "weighted avg       0.70      0.71      0.68        31\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: Combo1, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.74      0.80      0.77        46\n",
      "Unsuccessful       0.50      0.41      0.45        22\n",
      "\n",
      "    accuracy                           0.68        68\n",
      "   macro avg       0.62      0.61      0.61        68\n",
      "weighted avg       0.66      0.68      0.67        68\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping Combo2 with variables ['ERM_SCORE'] due to NaN values.\n",
      "Skipping Combo2 with variables ['hs_gpa', 'ERM_SCORE'] due to NaN values.\n",
      "Course Level: Combo2, Variables: ['sat_new_math']\n",
      "Accuracy: 0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.67      0.75      0.71         8\n",
      "Unsuccessful       0.00      0.00      1.00         3\n",
      "\n",
      "    accuracy                           0.55        11\n",
      "   macro avg       0.33      0.38      0.85        11\n",
      "weighted avg       0.48      0.55      0.79        11\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: Combo2, Variables: ['act_math']\n",
      "Accuracy: 0.44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.53      0.60      0.56        15\n",
      "Unsuccessful       0.25      0.20      0.22        10\n",
      "\n",
      "    accuracy                           0.44        25\n",
      "   macro avg       0.39      0.40      0.39        25\n",
      "weighted avg       0.42      0.44      0.43        25\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: Combo2, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.80      1.00      0.89         8\n",
      "Unsuccessful       1.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.90      0.50      0.44        10\n",
      "weighted avg       0.84      0.80      0.71        10\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: Combo2, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.50      0.77      0.61        13\n",
      "Unsuccessful       0.25      0.09      0.13        11\n",
      "\n",
      "    accuracy                           0.46        24\n",
      "   macro avg       0.38      0.43      0.37        24\n",
      "weighted avg       0.39      0.46      0.39        24\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping Combo3 with variables ['ERM_SCORE'] due to NaN values.\n",
      "Skipping Combo3 with variables ['hs_gpa', 'ERM_SCORE'] due to NaN values.\n",
      "Course Level: Combo3, Variables: ['sat_new_math']\n",
      "Accuracy: 0.57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.57      1.00      0.73        69\n",
      "Unsuccessful       1.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.57       121\n",
      "   macro avg       0.79      0.50      0.36       121\n",
      "weighted avg       0.75      0.57      0.41       121\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping Combo3 with variables ['act_math'] due to NaN values.\n",
      "Course Level: Combo3, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.62      0.82      0.71        67\n",
      "Unsuccessful       0.52      0.28      0.36        47\n",
      "\n",
      "    accuracy                           0.60       114\n",
      "   macro avg       0.57      0.55      0.53       114\n",
      "weighted avg       0.58      0.60      0.56       114\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping Combo3 with variables ['hs_gpa', 'act_math'] due to NaN values.\n"
     ]
    }
   ],
   "source": [
    "# Define base courses and course combinations\n",
    "base_courses = ['088', '216Q', '132', '161Q', '151Q', '165Q', '171Q']\n",
    "course_combinations = {\n",
    "    'Combo1': ('005', '105Q'),\n",
    "    'Combo2': ('063', '090'),\n",
    "    'Combo3': ('021', '121Q')\n",
    "}\n",
    "\n",
    "# Add '105Q', '090', '121Q' conditionally based on campus_code\n",
    "courses_to_check = ['105Q', '090', '121Q']\n",
    "for course in courses_to_check:\n",
    "    if df_merged[(df_merged['campus_code'] != 'ZGC') & (df_merged['course_number'] == course)].shape[0] > 0:\n",
    "        base_courses.append(course)\n",
    "\n",
    "# Combine individual courses with combination labels for iteration\n",
    "included_courses = base_courses + list(course_combinations.keys())\n",
    "\n",
    "# Filtering DataFrame based on updated logic\n",
    "def filter_df(df, course_key):\n",
    "    # For combinations, select rows matching any of the combination courses\n",
    "    if course_key in course_combinations:\n",
    "        return df[df['course_number'].isin(course_combinations[course_key])]\n",
    "    # For individual courses, simply filter by the course number\n",
    "    else:\n",
    "        return df[df['course_number'] == course_key]\n",
    "\n",
    "# Define the combinations of X variables you want to explore\n",
    "x_variable_combinations = [\n",
    "    ['ERM_SCORE'],\n",
    "    ['hs_gpa', 'ERM_SCORE'],\n",
    "    ['sat_new_math'],\n",
    "    ['act_math'],\n",
    "    ['hs_gpa', 'sat_new_math'],\n",
    "    ['hs_gpa', 'act_math']\n",
    "]\n",
    "\n",
    "# Initialize model storage with an additional level for variable combinations\n",
    "models = {}\n",
    "\n",
    "for course_key in included_courses:\n",
    "    df_filtered = filter_df(df_merged, course_key)\n",
    "    if df_filtered.empty:\n",
    "        print(f\"No data for {course_key}\")\n",
    "        continue\n",
    "\n",
    "    # Iterate through each combination of X variables\n",
    "    for x_vars in x_variable_combinations:\n",
    "        X = df_filtered[x_vars].dropna()  # Ensure no NaN values in predictors\n",
    "        y = df_filtered.loc[X.index, 'grade_category']\n",
    "        \n",
    "        # Drop rows with NaN in any of the specified 'X' variables\n",
    "        y = df_filtered.loc[X.index, 'grade_category']\n",
    "        \n",
    "        # Ensure 'y' is aligned with 'X' after dropping NaNs\n",
    "        X = X.dropna()\n",
    "        \n",
    "        \n",
    "        if X.empty or y.isnull().any():\n",
    "            print(f\"Skipping {course_key} with variables {x_vars} due to NaN values.\")\n",
    "            continue\n",
    "\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "        # Check if y_encoded contains more than one unique class\n",
    "        if len(np.unique(y_encoded)) < 2:\n",
    "            print(f\"Skipping {course_key} with variables {x_vars} because the data contains only one class after encoding.\")\n",
    "            continue\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.20, random_state=42)\n",
    "\n",
    "        log_reg = LogisticRegression(max_iter=1000)\n",
    "        try:\n",
    "            log_reg.fit(X_train, y_train)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error fitting model for {course_key} with variables {x_vars}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        y_pred = log_reg.predict(X_test)\n",
    "\n",
    "        unique_y_test = set(y_test)\n",
    "        unique_y_pred = set(y_pred)\n",
    "        unique_classes = unique_y_test.union(unique_y_pred)\n",
    "        target_names = label_encoder.inverse_transform(list(unique_classes))\n",
    "\n",
    "        print(f'Course Level: {course_key}, Variables: {x_vars}')\n",
    "        print(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')\n",
    "        print(classification_report(y_test, y_pred, labels=list(unique_classes), target_names=target_names, zero_division=1))\n",
    "        print(\"--------------------\\n\")\n",
    "\n",
    "        models[(course_key, tuple(x_vars))] = log_reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Logistic Regression Model - Courses/Combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 088 with variables ['ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Skipping 088 with variables ['hs_gpa', 'ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Error fitting model for 088 with variables ['sat_new_math']: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1\n",
      "Course/Combo: 088, Variables: ['act_math']\n",
      "Accuracy: 0.50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.56      0.83      0.67         6\n",
      "Unsuccessful       0.00      0.00      1.00         4\n",
      "\n",
      "    accuracy                           0.50        10\n",
      "   macro avg       0.28      0.42      0.83        10\n",
      "weighted avg       0.33      0.50      0.80        10\n",
      "\n",
      "--------------------\n",
      "\n",
      "Error fitting model for 088 with variables ['hs_gpa', 'sat_new_math']: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1\n",
      "Course/Combo: 088, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       1.00      0.75      0.86         4\n",
      "Unsuccessful       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.92      0.88      0.88         9\n",
      "weighted avg       0.91      0.89      0.89         9\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping 216Q with variables ['ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Skipping 216Q with variables ['hs_gpa', 'ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Course/Combo: 216Q, Variables: ['sat_new_math']\n",
      "Accuracy: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.71      0.99      0.83        80\n",
      "Unsuccessful       0.93      0.29      0.44        45\n",
      "\n",
      "    accuracy                           0.74       125\n",
      "   macro avg       0.82      0.64      0.63       125\n",
      "weighted avg       0.79      0.74      0.69       125\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 216Q, Variables: ['act_math']\n",
      "Accuracy: 0.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.63      0.91      0.75       118\n",
      "Unsuccessful       0.74      0.33      0.46        93\n",
      "\n",
      "    accuracy                           0.65       211\n",
      "   macro avg       0.69      0.62      0.60       211\n",
      "weighted avg       0.68      0.65      0.62       211\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 216Q, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.80      0.89      0.84        84\n",
      "Unsuccessful       0.61      0.42      0.50        33\n",
      "\n",
      "    accuracy                           0.76       117\n",
      "   macro avg       0.70      0.66      0.67       117\n",
      "weighted avg       0.74      0.76      0.75       117\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 216Q, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.73      0.84      0.78       117\n",
      "Unsuccessful       0.68      0.53      0.59        76\n",
      "\n",
      "    accuracy                           0.72       193\n",
      "   macro avg       0.70      0.68      0.69       193\n",
      "weighted avg       0.71      0.72      0.71       193\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping 132 with variables ['ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Skipping 132 with variables ['hs_gpa', 'ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Course/Combo: 132, Variables: ['sat_new_math']\n",
      "Accuracy: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 132, Variables: ['act_math']\n",
      "Accuracy: 0.59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.59      1.00      0.74        10\n",
      "Unsuccessful       1.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.59        17\n",
      "   macro avg       0.79      0.50      0.37        17\n",
      "weighted avg       0.76      0.59      0.44        17\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 132, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 132, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.86      1.00      0.92        12\n",
      "Unsuccessful       1.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.93      0.50      0.46        14\n",
      "weighted avg       0.88      0.86      0.79        14\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping 161Q with variables ['ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Skipping 161Q with variables ['hs_gpa', 'ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Course/Combo: 161Q, Variables: ['sat_new_math']\n",
      "Accuracy: 0.60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.61      0.89      0.72        54\n",
      "Unsuccessful       0.54      0.18      0.27        38\n",
      "\n",
      "    accuracy                           0.60        92\n",
      "   macro avg       0.57      0.54      0.50        92\n",
      "weighted avg       0.58      0.60      0.54        92\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 161Q, Variables: ['act_math']\n",
      "Accuracy: 0.76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.79      0.87      0.83       101\n",
      "Unsuccessful       0.68      0.54      0.60        52\n",
      "\n",
      "    accuracy                           0.76       153\n",
      "   macro avg       0.73      0.70      0.71       153\n",
      "weighted avg       0.75      0.76      0.75       153\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 161Q, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.76      0.88      0.81        57\n",
      "Unsuccessful       0.67      0.47      0.55        30\n",
      "\n",
      "    accuracy                           0.74        87\n",
      "   macro avg       0.71      0.67      0.68        87\n",
      "weighted avg       0.73      0.74      0.72        87\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 161Q, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.80      0.87      0.83        91\n",
      "Unsuccessful       0.71      0.60      0.65        50\n",
      "\n",
      "    accuracy                           0.77       141\n",
      "   macro avg       0.76      0.73      0.74       141\n",
      "weighted avg       0.77      0.77      0.77       141\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping 151Q with variables ['ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Skipping 151Q with variables ['hs_gpa', 'ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Course/Combo: 151Q, Variables: ['sat_new_math']\n",
      "Accuracy: 0.58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.58      0.97      0.73        29\n",
      "Unsuccessful       0.50      0.05      0.09        21\n",
      "\n",
      "    accuracy                           0.58        50\n",
      "   macro avg       0.54      0.51      0.41        50\n",
      "weighted avg       0.55      0.58      0.46        50\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 151Q, Variables: ['act_math']\n",
      "Accuracy: 0.58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.61      0.92      0.73        48\n",
      "Unsuccessful       0.20      0.03      0.06        29\n",
      "\n",
      "    accuracy                           0.58        77\n",
      "   macro avg       0.41      0.48      0.40        77\n",
      "weighted avg       0.46      0.58      0.48        77\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 151Q, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.76      0.84      0.80        31\n",
      "Unsuccessful       0.64      0.53      0.58        17\n",
      "\n",
      "    accuracy                           0.73        48\n",
      "   macro avg       0.70      0.68      0.69        48\n",
      "weighted avg       0.72      0.73      0.72        48\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 151Q, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.78      0.87      0.82        53\n",
      "Unsuccessful       0.50      0.35      0.41        20\n",
      "\n",
      "    accuracy                           0.73        73\n",
      "   macro avg       0.64      0.61      0.62        73\n",
      "weighted avg       0.70      0.73      0.71        73\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping 165Q with variables ['ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Skipping 165Q with variables ['hs_gpa', 'ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Course/Combo: 165Q, Variables: ['sat_new_math']\n",
      "Accuracy: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       1.00      0.67      0.80         3\n",
      "Unsuccessful       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.80         5\n",
      "   macro avg       0.83      0.83      0.80         5\n",
      "weighted avg       0.87      0.80      0.80         5\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 165Q, Variables: ['act_math']\n",
      "Accuracy: 0.50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.44      1.00      0.62         4\n",
      "Unsuccessful       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.50        10\n",
      "   macro avg       0.72      0.58      0.45        10\n",
      "weighted avg       0.78      0.50      0.42        10\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 165Q, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       1.00      0.33      0.50         3\n",
      "Unsuccessful       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.75      0.67      0.58         5\n",
      "weighted avg       0.80      0.60      0.57         5\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 165Q, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.57      0.80      0.67         5\n",
      "Unsuccessful       0.50      0.25      0.33         4\n",
      "\n",
      "    accuracy                           0.56         9\n",
      "   macro avg       0.54      0.53      0.50         9\n",
      "weighted avg       0.54      0.56      0.52         9\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping 171Q with variables ['ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Skipping 171Q with variables ['hs_gpa', 'ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Course/Combo: 171Q, Variables: ['sat_new_math']\n",
      "Accuracy: 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.79      0.96      0.87        54\n",
      "Unsuccessful       0.75      0.30      0.43        20\n",
      "\n",
      "    accuracy                           0.78        74\n",
      "   macro avg       0.77      0.63      0.65        74\n",
      "weighted avg       0.78      0.78      0.75        74\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 171Q, Variables: ['act_math']\n",
      "Accuracy: 0.70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.75      0.87      0.81        79\n",
      "Unsuccessful       0.47      0.28      0.35        32\n",
      "\n",
      "    accuracy                           0.70       111\n",
      "   macro avg       0.61      0.58      0.58       111\n",
      "weighted avg       0.67      0.70      0.68       111\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 171Q, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.68      0.91      0.78        43\n",
      "Unsuccessful       0.71      0.36      0.48        28\n",
      "\n",
      "    accuracy                           0.69        71\n",
      "   macro avg       0.70      0.63      0.63        71\n",
      "weighted avg       0.70      0.69      0.66        71\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 171Q, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.69      0.92      0.79        60\n",
      "Unsuccessful       0.78      0.42      0.55        43\n",
      "\n",
      "    accuracy                           0.71       103\n",
      "   macro avg       0.74      0.67      0.67       103\n",
      "weighted avg       0.73      0.71      0.69       103\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping 105Q with variables ['ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Skipping 105Q with variables ['hs_gpa', 'ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Course/Combo: 105Q, Variables: ['sat_new_math']\n",
      "Accuracy: 0.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.68      1.00      0.81        13\n",
      "Unsuccessful       1.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.68        19\n",
      "   macro avg       0.84      0.50      0.41        19\n",
      "weighted avg       0.78      0.68      0.56        19\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 105Q, Variables: ['act_math']\n",
      "Accuracy: 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Ignore       1.00      0.00      0.00         2\n",
      "  Successful       0.70      0.96      0.81        27\n",
      "Unsuccessful       0.75      0.25      0.38        12\n",
      "\n",
      "    accuracy                           0.71        41\n",
      "   macro avg       0.82      0.40      0.40        41\n",
      "weighted avg       0.73      0.71      0.64        41\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 105Q, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.87      0.93      0.90        14\n",
      "Unsuccessful       0.67      0.50      0.57         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.77      0.71      0.73        18\n",
      "weighted avg       0.82      0.83      0.82        18\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 105Q, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.84      0.91      0.87        23\n",
      "Unsuccessful       0.82      0.69      0.75        13\n",
      "\n",
      "    accuracy                           0.83        36\n",
      "   macro avg       0.83      0.80      0.81        36\n",
      "weighted avg       0.83      0.83      0.83        36\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping 090 with variables ['ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Skipping 090 with variables ['hs_gpa', 'ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Course/Combo: 090, Variables: ['sat_new_math']\n",
      "Accuracy: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Unsuccessful       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 090, Variables: ['act_math']\n",
      "Accuracy: 0.70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       1.00      0.00      0.00         3\n",
      "Unsuccessful       0.70      1.00      0.82         7\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.85      0.50      0.41        10\n",
      "weighted avg       0.79      0.70      0.58        10\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 090, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       1.00      0.00      0.00         1\n",
      "Unsuccessful       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.88      0.50      0.43         4\n",
      "weighted avg       0.81      0.75      0.64         4\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 090, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.50      0.25      0.33         4\n",
      "Unsuccessful       0.57      0.80      0.67         5\n",
      "\n",
      "    accuracy                           0.56         9\n",
      "   macro avg       0.54      0.53      0.50         9\n",
      "weighted avg       0.54      0.56      0.52         9\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping 121Q with variables ['ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Skipping 121Q with variables ['hs_gpa', 'ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Course/Combo: 121Q, Variables: ['sat_new_math']\n",
      "Accuracy: 0.46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.46      1.00      0.63        32\n",
      "Unsuccessful       1.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.46        70\n",
      "   macro avg       0.73      0.50      0.31        70\n",
      "weighted avg       0.75      0.46      0.29        70\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 121Q, Variables: ['act_math']\n",
      "Accuracy: 0.62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.63      0.81      0.71        62\n",
      "Unsuccessful       0.60      0.38      0.47        47\n",
      "\n",
      "    accuracy                           0.62       109\n",
      "   macro avg       0.62      0.59      0.59       109\n",
      "weighted avg       0.62      0.62      0.61       109\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 121Q, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.71      0.73      0.72        33\n",
      "Unsuccessful       0.72      0.70      0.71        33\n",
      "\n",
      "    accuracy                           0.71        66\n",
      "   macro avg       0.71      0.71      0.71        66\n",
      "weighted avg       0.71      0.71      0.71        66\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: 121Q, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.62      0.84      0.71        50\n",
      "Unsuccessful       0.74      0.47      0.58        49\n",
      "\n",
      "    accuracy                           0.66        99\n",
      "   macro avg       0.68      0.65      0.64        99\n",
      "weighted avg       0.68      0.66      0.64        99\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping Combo1 with variables ['ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Skipping Combo1 with variables ['hs_gpa', 'ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Course/Combo: Combo1, Variables: ['sat_new_math']\n",
      "Accuracy: 0.67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.71      0.92      0.80        24\n",
      "Unsuccessful       0.00      0.00      1.00         9\n",
      "\n",
      "    accuracy                           0.67        33\n",
      "   macro avg       0.35      0.46      0.90        33\n",
      "weighted avg       0.52      0.67      0.85        33\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: Combo1, Variables: ['act_math']\n",
      "Accuracy: 0.61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Ignore       1.00      0.00      0.00         2\n",
      "  Successful       0.59      0.98      0.74        42\n",
      "Unsuccessful       0.83      0.16      0.27        31\n",
      "\n",
      "    accuracy                           0.61        75\n",
      "   macro avg       0.81      0.38      0.34        75\n",
      "weighted avg       0.70      0.61      0.53        75\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: Combo1, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.72      0.90      0.80        20\n",
      "Unsuccessful       0.67      0.36      0.47        11\n",
      "\n",
      "    accuracy                           0.71        31\n",
      "   macro avg       0.69      0.63      0.64        31\n",
      "weighted avg       0.70      0.71      0.68        31\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: Combo1, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.74      0.80      0.77        46\n",
      "Unsuccessful       0.50      0.41      0.45        22\n",
      "\n",
      "    accuracy                           0.68        68\n",
      "   macro avg       0.62      0.61      0.61        68\n",
      "weighted avg       0.66      0.68      0.67        68\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping Combo2 with variables ['ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Skipping Combo2 with variables ['hs_gpa', 'ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Course/Combo: Combo2, Variables: ['sat_new_math']\n",
      "Accuracy: 0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.67      0.75      0.71         8\n",
      "Unsuccessful       0.00      0.00      1.00         3\n",
      "\n",
      "    accuracy                           0.55        11\n",
      "   macro avg       0.33      0.38      0.85        11\n",
      "weighted avg       0.48      0.55      0.79        11\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: Combo2, Variables: ['act_math']\n",
      "Accuracy: 0.44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.53      0.60      0.56        15\n",
      "Unsuccessful       0.25      0.20      0.22        10\n",
      "\n",
      "    accuracy                           0.44        25\n",
      "   macro avg       0.39      0.40      0.39        25\n",
      "weighted avg       0.42      0.44      0.43        25\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: Combo2, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.80      1.00      0.89         8\n",
      "Unsuccessful       1.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.90      0.50      0.44        10\n",
      "weighted avg       0.84      0.80      0.71        10\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: Combo2, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.50      0.77      0.61        13\n",
      "Unsuccessful       0.25      0.09      0.13        11\n",
      "\n",
      "    accuracy                           0.46        24\n",
      "   macro avg       0.38      0.43      0.37        24\n",
      "weighted avg       0.39      0.46      0.39        24\n",
      "\n",
      "--------------------\n",
      "\n",
      "Skipping Combo3 with variables ['ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Skipping Combo3 with variables ['hs_gpa', 'ERM_SCORE'] due to insufficient data after dropping NaNs.\n",
      "Course/Combo: Combo3, Variables: ['sat_new_math']\n",
      "Accuracy: 0.57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.57      1.00      0.73        69\n",
      "Unsuccessful       1.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.57       121\n",
      "   macro avg       0.79      0.50      0.36       121\n",
      "weighted avg       0.75      0.57      0.41       121\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: Combo3, Variables: ['act_math']\n",
      "Accuracy: 0.53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.53      1.00      0.69       107\n",
      "Unsuccessful       1.00      0.00      0.00        95\n",
      "\n",
      "    accuracy                           0.53       202\n",
      "   macro avg       0.76      0.50      0.35       202\n",
      "weighted avg       0.75      0.53      0.37       202\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: Combo3, Variables: ['hs_gpa', 'sat_new_math']\n",
      "Accuracy: 0.60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.62      0.82      0.71        67\n",
      "Unsuccessful       0.52      0.28      0.36        47\n",
      "\n",
      "    accuracy                           0.60       114\n",
      "   macro avg       0.57      0.55      0.53       114\n",
      "weighted avg       0.58      0.60      0.56       114\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course/Combo: Combo3, Variables: ['hs_gpa', 'act_math']\n",
      "Accuracy: 0.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Ignore       1.00      0.00      0.00         1\n",
      "  Successful       0.70      0.81      0.75       119\n",
      "Unsuccessful       0.51      0.37      0.43        67\n",
      "\n",
      "    accuracy                           0.65       187\n",
      "   macro avg       0.74      0.39      0.39       187\n",
      "weighted avg       0.63      0.65      0.63       187\n",
      "\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the combinations of X variables you want to explore\n",
    "x_variable_combinations = [\n",
    "    ['ERM_SCORE'],\n",
    "    ['hs_gpa','ERM_SCORE'],\n",
    "    ['sat_new_math'],\n",
    "    ['act_math'],\n",
    "    ['hs_gpa', 'sat_new_math'],\n",
    "    ['hs_gpa', 'act_math']\n",
    "]\n",
    "\n",
    "# Initialize model storage with an additional level for variable combinations\n",
    "models = {}\n",
    "\n",
    "for course_key in included_courses:\n",
    "    df_filtered = filter_df(df_merged, course_key)\n",
    "    if df_filtered.empty:\n",
    "        print(f\"No data for course number {course_key}\")\n",
    "        continue\n",
    "\n",
    "    # Iterate through each combination of X variables\n",
    "    for x_vars in x_variable_combinations:\n",
    "        # Attempt to select specified variables; handle missing variables by skipping\n",
    "        try:\n",
    "            X = df_filtered[x_vars]\n",
    "        except KeyError:\n",
    "            print(f\"Skipping {course_key} due to missing one of the variables: {x_vars}\")\n",
    "            continue\n",
    "\n",
    "        # Drop rows with NaN in any of the specified 'X' variables\n",
    "        X = X.dropna(how='any')\n",
    "        \n",
    "        # Ensure 'y' is aligned with 'X' after dropping NaNs\n",
    "        y = df_filtered.loc[X.index, 'grade_category'].dropna()\n",
    "        \n",
    "        # Ensure the same indices are used for both X and y after dropna to avoid issues in train_test_split\n",
    "        X = X.loc[y.index]\n",
    "\n",
    "        if X.empty or y.empty:\n",
    "            print(f\"Skipping {course_key} with variables {x_vars} due to insufficient data after dropping NaNs.\")\n",
    "            continue\n",
    "\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "        # Check if y_encoded contains more than one unique class\n",
    "        if len(np.unique(y_encoded)) < 2:\n",
    "            print(f\"Skipping {course_key} with variables {x_vars} because the data contains only one class after encoding.\")\n",
    "            continue\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.20, random_state=42)\n",
    "\n",
    "        log_reg = LogisticRegression(max_iter=1000)\n",
    "        try:\n",
    "            log_reg.fit(X_train, y_train)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error fitting model for {course_key} with variables {x_vars}: {e}\")\n",
    "            continue\n",
    "\n",
    "        y_pred = log_reg.predict(X_test)\n",
    "\n",
    "        unique_y_test = set(y_test)\n",
    "        unique_y_pred = set(y_pred)\n",
    "        unique_classes = unique_y_test.union(unique_y_pred)\n",
    "        target_names = label_encoder.inverse_transform(list(unique_classes))\n",
    "\n",
    "        print(f'Course/Combo: {course_key}, Variables: {x_vars}')\n",
    "        print(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')\n",
    "        print(classification_report(y_test, y_pred, labels=list(unique_classes), target_names=target_names, zero_division=1))\n",
    "        print(\"--------------------\\n\")\n",
    "\n",
    "        # Store the trained model with variable combination as part of the key\n",
    "        models[(course_key, tuple(x_vars))] = log_reg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [0, 7359]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Training and testing split\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Train a decision tree classifier\u001b[39;00m\n\u001b[0;32m     12\u001b[0m clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:2646\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2646\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2648\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2649\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2650\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2651\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:453\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    452\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 453\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [0, 7359]"
     ]
    }
   ],
   "source": [
    "# Now prepare your predictors (X) and target (y) using the cleaned DataFrame\n",
    "X = df_merged[['hs_gpa', 'ERM_SCORE']]\n",
    "y = df_merged['course_level']\n",
    "\n",
    "# Ensure no NaN values in predictors\n",
    "X = X.dropna()\n",
    "\n",
    "# Training and testing split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a decision tree classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4:  Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode the target variable 'course_number'\n",
    "course_number_encoder = LabelEncoder()\n",
    "df_merged['encoded_course_level'] = course_number_encoder.fit_transform(df_merged['course_level'])\n",
    "\n",
    "# Predictors\n",
    "X = df_merged[['hs_gpa', 'ERM_SCORE']]\n",
    "\n",
    "# Target variable is'course_number_encoded'\n",
    "y_course_number = df_merged['encoded_course_level']\n",
    "\n",
    "# Ensure no NaN values in predictors\n",
    "X = X.dropna()\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train_course_number, y_test_course_number = train_test_split(X, y_course_number, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the DecisionTreeClassifier with parameters to control tree complexity\n",
    "clf_course_number = DecisionTreeClassifier(\n",
    "    max_depth=5,               # Limit the depth of the tree\n",
    "    min_samples_split=40,      # Require at least 40 samples to split a node\n",
    "    min_samples_leaf=20,       # Each leaf node must contain at least 20 samples\n",
    "    max_leaf_nodes=15,         # Limit the total number of leaf nodes\n",
    "    random_state=42\n",
    ")\n",
    "# Fit the classifier to the training data\n",
    "clf_course_number.fit(X_train, y_train_course_number)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_course_number = clf_course_number.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the predicted course numbers back to the original encoding\n",
    "predicted_courses = course_number_encoder.inverse_transform(y_pred_course_number)\n",
    "\n",
    "# Add the predicted courses to test DataFrame\n",
    "X_test.loc[:,'test_score'] = predicted_courses\n",
    "\n",
    "# Join the original 'grade_category' to the test DataFrame for evaluation\n",
    "X_test = X_test.join(df_merged['grade_category'], how='left')\n",
    "\n",
    "# Evaluate the success by checking the grade_category of the predicted placements\n",
    "successful_placements = X_test[X_test['grade_category'] == 'Successful']\n",
    "success_rate = len(successful_placements) / len(X_test)\n",
    "print(f'Success rate of placements: {success_rate:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(40,10))\n",
    "plot_tree(clf_course_number, \n",
    "          feature_names=X_train.columns, \n",
    "          class_names=course_number_encoder.classes_.astype(str),  # Ensure class names are string\n",
    "          filled=True, rounded=True, \n",
    "          fontsize=12)\n",
    "\n",
    "\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Encode the target variable\n",
    "course_number_encoder = LabelEncoder()\n",
    "df_merged['course_level_encoded'] = course_number_encoder.fit_transform(df_merged['test_score'])\n",
    "\n",
    "#Prepare the data\n",
    "X = df_merged[['ERM_SCORE', 'hs_gpa']]\n",
    "y = df_merged['course_level_encoded'] \n",
    "\n",
    "# Ensure no NaN values in predictors\n",
    "X = X.dropna()\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Continue with initializing and fitting your XGBoost classifier\n",
    "xgb_model_course_number = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model_course_number.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_course_number = xgb_model_course_number.predict(X_test)\n",
    "\n",
    "# Decode the predicted course numbers back to the original course numbers for interpretability\n",
    "predicted_course_numbers = course_number_encoder.inverse_transform(y_pred_course_number)\n",
    "\n",
    "# Evaluate the predictions\n",
    "accuracy = accuracy_score(y_test, y_pred_course_number)  # This comparison should now be valid\n",
    "print(f'Accuracy of the XGBoost model for course number prediction: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the unique encoded labels back to original string labels\n",
    "# Ensure original_class_labels are strings\n",
    "original_class_labels_str = [str(label) for label in course_number_encoder.inverse_transform(df_merged['course_level_encoded'].unique())]\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_course_number, target_names=original_class_labels_str))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_course_number)\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=course_number_encoder.classes_, yticklabels=course_number_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
