{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier , plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.impute import SimpleImputer  \n",
    "\n",
    "# Read the math placement data from the Excel file\n",
    "df_math_placement = pd.read_excel('math_placement.xlsx')\n",
    "\n",
    "# Read the edready raw scores data from the CSV file\n",
    "df_ed_ready = pd.read_csv('edready_raw_scores.csv')\n",
    "\n",
    "# Load the file of incoming students\n",
    "#incoming_students = pd.read_csv('incoming_students.csv')will need to change to correct file name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_cleaned = df_math_placement.copy()\n",
    "\n",
    "# Define the mapping of grades to grade categories\n",
    "grade_mapping = {\n",
    "    \"A\": \"Successful\", \"B\": \"Successful\", \"B+\": \"Successful\",\n",
    "    \"A-\": \"Successful\", \"B*\": \"Successful\", \"A*\": \"Successful\",\n",
    "    \"B+*\": \"Successful\", \"W\": \"Unsuccessful\", \"C-\": \"Unsuccessful\",\n",
    "    \"F\": \"Unsuccessful\", \"B-\": \"Successful\", \"C+\": \"Unsuccessful\",\n",
    "    \"D\": \"Unsuccessful\", \"D*\": \"Unsuccessful\", \"C\": \"Unsuccessful\",\n",
    "    \"W*\": \"Unsuccessful\", \"P*\": \"Successful\", \"C+*\": \"Unsuccessful\",\n",
    "    \"F*\": \"Unsuccessful\", \"D+\": \"Unsuccessful\", \"P\": \"Successful\",\n",
    "    \"C*\": \"Unsuccessful\", \"A-*\": \"Successful\", \"I\": \"Unsuccessful\",\n",
    "    \"AU\": \"Ignore\", \"B-*\": \"Successful\", \"D-\": \"Unsuccessful\",\n",
    "    \"NR\": \"Ignore\", \"C-*\": \"Unsuccessful\", \"I*\": \"Unsuccessful\",\n",
    "    \"NR*\": \"Ignore\"\n",
    "}\n",
    "\n",
    "# Map the grades to their categories and append as a new column\n",
    "df_cleaned['grade_category'] = df_cleaned['grade'].map(grade_mapping)\n",
    "\n",
    "\n",
    "# Define base courses and adjust the list based on 'campus_code'\n",
    "base_courses = ['088', '216Q', '132', '161Q', '151Q', '165Q', '171Q']\n",
    "courses_to_check = ['105Q', '090', '121Q']\n",
    "\n",
    "for course in courses_to_check:\n",
    "    if df_cleaned[(df_cleaned['campus_code'] != 'ZGC') & (df_cleaned['course_number'] == course)].shape[0] > 0:\n",
    "        base_courses.append(course)\n",
    "\n",
    "# Define course combinations\n",
    "course_combinations = {\n",
    "    'Combo1': ('005', '105Q'),\n",
    "    'Combo2': ('063', '090'),\n",
    "    'Combo3': ('021', '121Q')\n",
    "}\n",
    "\n",
    "# Map courses and combinations to levels\n",
    "course_levels = {\n",
    "    '088': 100,\n",
    "    'Combo2': 100,  # ('063', '090')\n",
    "    'Combo1': 150,  # ('005', '105Q')\n",
    "    '090': 150,\n",
    "    'Combo3': 250,  # ('021', '121Q')\n",
    "    '105Q': 290,\n",
    "    '216Q': 300,\n",
    "    '132': 300,\n",
    "    '121Q': 300,\n",
    "    '161Q': 400,\n",
    "    '151Q': 400,\n",
    "    '165Q': 500,\n",
    "    '171Q': 500\n",
    "}\n",
    "\n",
    "# Function to determine course level based on the course number or combination\n",
    "def determine_course_level(course_number, campus_code):\n",
    "    # Handle special cases for '105Q', '090', '121Q' based on 'campus_code'\n",
    "    if course_number in ['105Q', '090', '121Q'] and campus_code == 'ZGC':\n",
    "        # Exclude these courses for ZGC campus\n",
    "        return None\n",
    "    for combo_name, combo_courses in course_combinations.items():\n",
    "        if course_number in combo_courses:\n",
    "            # Return the level for the course combination\n",
    "            return course_levels[combo_name]\n",
    "    # Return the level for individual courses\n",
    "    return course_levels.get(course_number)\n",
    "\n",
    "# Apply the function to each row in df_cleaned to create a new 'course_level' column\n",
    "df_cleaned['course_level'] = df_cleaned.apply(lambda row: determine_course_level(row['course_number'], row['campus_code']), axis=1)\n",
    "\n",
    "# Create a new column to store the PIDM, course number, and term as a single string\n",
    "df_cleaned['PIDM_course_number_term'] = df_cleaned['PIDM'].astype(str) + '_' + df_cleaned['course_number'].astype(str) + '_' + df_cleaned['term'].astype(str)\n",
    "\n",
    "# Remove duplicates based on the new column\n",
    "df_cleaned = df_cleaned.drop_duplicates(subset='PIDM_course_number_term')\n",
    "\n",
    "# Make sure the column names match in both dataframes before merging\n",
    "df_cleaned.rename(columns={'pidm': 'PIDM'}, inplace=True)\n",
    "\n",
    "# Display the cleaned and imputed dataframe\n",
    "df_cleaned.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert 'term' to a numeric type to ensure correct sorting\n",
    "df_cleaned['term'] = pd.to_numeric(df_cleaned['term'])\n",
    "\n",
    "# Find the oldest term for each PIDM\n",
    "oldest_terms = df_cleaned.groupby('PIDM')['term'].min().reset_index()\n",
    "\n",
    "# Merge the oldest terms back to the original DataFrame to filter records\n",
    "df_oldest = pd.merge(df_cleaned, oldest_terms, on=['PIDM', 'term'], how='inner')\n",
    "\n",
    "# Now, df_oldest contains only the records of the oldest term for each PIDM,\n",
    "# including cases where there are multiple records for a PIDM within that oldest term\n",
    "\n",
    "# Sort PIDM\n",
    "df_oldest.sort_values(by=['PIDM', 'term'], ascending=[True, True], inplace=True)\n",
    "\n",
    "# Show the updated DataFrame\n",
    "df_oldest.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim whitespace from headers\n",
    "df_oldest.columns = df_oldest.columns.str.strip()\n",
    "df_ed_ready.columns = df_ed_ready.columns.str.strip()\n",
    "\n",
    "# Merge the two dataframes based on the PIDM\n",
    "df_merged = pd.merge(df_oldest, df_ed_ready[['PIDM', 'ERM_SCORE']], on='PIDM', how='left')\n",
    "\n",
    "# Drop NaN values from the 'hs_gpa' and 'ERM_SCORE' columns\n",
    "df_merged.dropna(subset=['ERM_SCORE','course_level','hs_gpa'], inplace=True)\n",
    "\n",
    "# Display the merged dataframe\n",
    "df_merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows in the merged dataframe\n",
    "num_rows = df_merged.shape[0]\n",
    "print(f\"Number of rows in df_merged: {num_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count the occurrences of each grade category\n",
    "grade_counts = df_merged['grade_category'].value_counts()\n",
    "\n",
    "# Display the count of each grade category\n",
    "print(grade_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'course_level' and then count occurrences of each 'grade_category' within each level\n",
    "grade_category_distribution = df_merged.groupby('course_level')['grade_category'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "# Display the distribution of grade categories within each course level\n",
    "print(grade_category_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Logistic Regression Model - ERM Score as Predictor Variable & Grade Category as Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base courses and course combinations\n",
    "base_courses = ['088', '216Q', '132', '161Q', '151Q', '165Q', '171Q']\n",
    "course_combinations = {\n",
    "    'Combo1': ('005', '105Q'),\n",
    "    'Combo2': ('063', '090'),\n",
    "    'Combo3': ('021', '121Q')\n",
    "}\n",
    "\n",
    "# Add '105Q', '090', '121Q' conditionally based on campus_code\n",
    "courses_to_check = ['105Q', '090', '121Q']\n",
    "for course in courses_to_check:\n",
    "    if df_merged[(df_merged['campus_code'] != 'ZGC') & (df_merged['course_number'] == course)].shape[0] > 0:\n",
    "        base_courses.append(course)\n",
    "\n",
    "# Combine individual courses with combination labels for iteration\n",
    "included_courses = base_courses + list(course_combinations.keys())\n",
    "\n",
    "# Filtering DataFrame based on updated logic\n",
    "def filter_df(df, course_key):\n",
    "    # For combinations, select rows matching any of the combination courses\n",
    "    if course_key in course_combinations:\n",
    "        return df[df['course_number'].isin(course_combinations[course_key])]\n",
    "    # For individual courses, simply filter by the course number\n",
    "    else:\n",
    "        return df[df['course_number'] == course_key]\n",
    "\n",
    "# Initialize model storage\n",
    "models = {}\n",
    "\n",
    "for course_key in included_courses:\n",
    "    df_filtered = filter_df(df_merged, course_key)\n",
    "    if df_filtered.empty:\n",
    "        print(f\"No data for {course_key}\")\n",
    "        continue\n",
    "\n",
    "    X = df_filtered[['ERM_SCORE']]\n",
    "    y = df_filtered['grade_category']\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.20, random_state=42)\n",
    "\n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "\n",
    "    # Handling mismatch in class sizes for the classification report\n",
    "    unique_y_test = set(y_test)\n",
    "    unique_y_pred = set(y_pred)\n",
    "    unique_classes = unique_y_test.union(unique_y_pred)\n",
    "    target_names = label_encoder.inverse_transform(list(unique_classes))\n",
    "\n",
    "    print(f'Course/Combo: {course_key}')\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')\n",
    "    print(classification_report(y_test, y_pred, labels=list(unique_classes), target_names=target_names, zero_division=1))\n",
    "    print(\"--------------------\\n\")\n",
    "\n",
    "    # Store the trained model\n",
    "    models[course_key] = log_reg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Logistic Regression Model - ERM Score & High School GPA as Predictor Variables & Grade Category as Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop NaN values from 'hs_gpa' and 'ERM_SCORE' columns\n",
    "df_merged.dropna(subset=['hs_gpa', 'ERM_SCORE'], inplace=True)\n",
    "\n",
    "# Define base courses and course combinations\n",
    "base_courses = ['088', '216Q', '132', '161Q', '151Q', '165Q', '171Q']\n",
    "course_combinations = {\n",
    "    'Combo1': ('005', '105Q'),\n",
    "    'Combo2': ('063', '090'),\n",
    "    'Combo3': ('021', '121Q')\n",
    "}\n",
    "\n",
    "# Add '105Q', '090', '121Q' conditionally based on campus_code\n",
    "courses_to_check = ['105Q', '090', '121Q']\n",
    "for course in courses_to_check:\n",
    "    if df_merged[(df_merged['campus_code'] != 'ZGC') & (df_merged['course_number'] == course)].shape[0] > 0:\n",
    "        base_courses.append(course)\n",
    "\n",
    "# Combine individual courses with combination labels for iteration\n",
    "included_courses = base_courses + list(course_combinations.keys())\n",
    "\n",
    "# Filtering DataFrame based on updated logic\n",
    "def filter_df(df, course_key):\n",
    "    # For combinations, select rows matching any of the combination courses\n",
    "    if course_key in course_combinations:\n",
    "        return df[df['course_number'].isin(course_combinations[course_key])]\n",
    "    # For individual courses, simply filter by the course number\n",
    "    else:\n",
    "        return df[df['course_number'] == course_key]\n",
    "\n",
    "# Now, `included_courses` correctly reflects the campus_code restriction for '105Q', '090', '121Q',\n",
    "# while `course_combinations` are processed to include all campus codes, including 'ZGC'.\n",
    "\n",
    "# Initialize model storage\n",
    "models = {}\n",
    "\n",
    "for course_key in included_courses:\n",
    "    # Use the filter_df function to filter the DataFrame\n",
    "    df_filtered = filter_df(df_merged, course_key)\n",
    "\n",
    "    if not df_filtered.empty:\n",
    "        X = df_filtered[['hs_gpa', 'ERM_SCORE']]\n",
    "        y = df_filtered['grade_category']\n",
    "\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.20, random_state=42)\n",
    "\n",
    "        log_reg = LogisticRegression(max_iter=1000)\n",
    "        log_reg.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = log_reg.predict(X_test)\n",
    "\n",
    "        # Handling mismatch in class sizes for the classification report\n",
    "        unique_y_test = set(y_test)\n",
    "        unique_y_pred = set(y_pred)\n",
    "        unique_classes = unique_y_test.union(unique_y_pred)\n",
    "        target_names = label_encoder.inverse_transform(list(unique_classes))\n",
    "\n",
    "        print(f'Course/Combo: {course_key}')\n",
    "        print(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')\n",
    "        print(classification_report(y_test, y_pred, labels=list(unique_classes), target_names=target_names, zero_division=0))\n",
    "        print(\"--------------------\\n\")\n",
    "\n",
    "        # Store the trained model\n",
    "        models[course_key] = log_reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Logistic Regression using ERM Score to predict success and course levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'course_level' is treated as a categorical variable with a finite set of unique values\n",
    "included_courses = df_merged['course_level'].unique()\n",
    "\n",
    "# Define a filter function based on 'course_level'\n",
    "def filter_df(df, course_level):\n",
    "    return df[df['course_level'] == course_level]\n",
    "\n",
    "# Initialize model storage\n",
    "models = {}\n",
    "\n",
    "# Iterate over unique course levels\n",
    "for course_level in included_courses:\n",
    "    df_filtered = filter_df(df_merged, course_level)\n",
    "    if df_filtered.empty:\n",
    "        print(f\"No data for course level {course_level}\")\n",
    "        continue\n",
    "\n",
    "    X = df_filtered[['ERM_SCORE']]\n",
    "    y = df_filtered['grade_category']\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.20, random_state=42)\n",
    "\n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "\n",
    "    # Handling mismatch in class sizes for the classification report\n",
    "    unique_y_test = set(y_test)\n",
    "    unique_y_pred = set(y_pred)\n",
    "    unique_classes = unique_y_test.union(unique_y_pred)\n",
    "    target_names = label_encoder.inverse_transform(list(unique_classes))\n",
    "\n",
    "    print(f'Course Level: {course_level}')\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')\n",
    "    print(classification_report(y_test, y_pred, labels=list(unique_classes), target_names=target_names, zero_division=1))\n",
    "    print(\"--------------------\\n\")\n",
    "\n",
    "    # Store the trained model\n",
    "    models[course_level] = log_reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Logistic Regression using ERM Score & High School GPA to predict success and course levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course Level: 100.0\n",
      "Accuracy: 0.63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.64      0.92      0.75        50\n",
      "Unsuccessful       0.56      0.16      0.25        31\n",
      "\n",
      "    accuracy                           0.63        81\n",
      "   macro avg       0.60      0.54      0.50        81\n",
      "weighted avg       0.61      0.63      0.56        81\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 250.0\n",
      "Accuracy: 0.63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.62      0.61      0.61       173\n",
      "Unsuccessful       0.64      0.65      0.65       187\n",
      "\n",
      "    accuracy                           0.63       360\n",
      "   macro avg       0.63      0.63      0.63       360\n",
      "weighted avg       0.63      0.63      0.63       360\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 300.0\n",
      "Accuracy: 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.70      0.70      0.70        40\n",
      "Unsuccessful       0.72      0.72      0.72        43\n",
      "\n",
      "    accuracy                           0.71        83\n",
      "   macro avg       0.71      0.71      0.71        83\n",
      "weighted avg       0.71      0.71      0.71        83\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 400.0\n",
      "Accuracy: 0.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.67      0.92      0.77       133\n",
      "Unsuccessful       0.71      0.31      0.43        87\n",
      "\n",
      "    accuracy                           0.68       220\n",
      "   macro avg       0.69      0.61      0.60       220\n",
      "weighted avg       0.69      0.68      0.64       220\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 150.0\n",
      "Accuracy: 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.76      0.82      0.79        39\n",
      "Unsuccessful       0.61      0.52      0.56        21\n",
      "\n",
      "    accuracy                           0.72        60\n",
      "   macro avg       0.69      0.67      0.68        60\n",
      "weighted avg       0.71      0.72      0.71        60\n",
      "\n",
      "--------------------\n",
      "\n",
      "Course Level: 500.0\n",
      "Accuracy: 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Successful       0.74      1.00      0.85        32\n",
      "Unsuccessful       1.00      0.39      0.56        18\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.87      0.69      0.71        50\n",
      "weighted avg       0.84      0.78      0.75        50\n",
      "\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'course_level' is treated as a categorical variable with a finite set of unique values\n",
    "included_courses = df_merged['course_level'].unique()\n",
    "\n",
    "# Define a filter function based on 'course_level'\n",
    "def filter_df(df, course_level):\n",
    "    return df[df['course_level'] == course_level]\n",
    "\n",
    "# Initialize model storage\n",
    "models = {}\n",
    "\n",
    "# Iterate over unique course levels\n",
    "for course_level in included_courses:\n",
    "    df_filtered = filter_df(df_merged, course_level)\n",
    "    if df_filtered.empty:\n",
    "        print(f\"No data for course level {course_level}\")\n",
    "        continue\n",
    "\n",
    "    X = df_filtered[['ERM_SCORE', 'hs_gpa']]\n",
    "    y = df_filtered['grade_category']\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.20, random_state=42)\n",
    "\n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "\n",
    "    # Handling mismatch in class sizes for the classification report\n",
    "    unique_y_test = set(y_test)\n",
    "    unique_y_pred = set(y_pred)\n",
    "    unique_classes = unique_y_test.union(unique_y_pred)\n",
    "    target_names = label_encoder.inverse_transform(list(unique_classes))\n",
    "\n",
    "    print(f'Course Level: {course_level}')\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')\n",
    "    print(classification_report(y_test, y_pred, labels=list(unique_classes), target_names=target_names, zero_division=1))\n",
    "    print(\"--------------------\\n\")\n",
    "\n",
    "    # Store the trained model\n",
    "    models[course_level] = log_reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       100.0       0.77      0.85      0.81        73\n",
      "       150.0       0.26      0.07      0.11        75\n",
      "       250.0       0.69      0.89      0.78       340\n",
      "       300.0       0.18      0.05      0.07        88\n",
      "       400.0       0.63      0.76      0.69       232\n",
      "       500.0       0.09      0.02      0.04        44\n",
      "\n",
      "    accuracy                           0.65       852\n",
      "   macro avg       0.44      0.44      0.41       852\n",
      "weighted avg       0.56      0.65      0.59       852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Now prepare your predictors (X) and target (y) using the cleaned DataFrame\n",
    "X = df_merged[['hs_gpa', 'ERM_SCORE']]\n",
    "y = df_merged['course_level']\n",
    "\n",
    "# Training and testing split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a decision tree classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4:  Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure no NaN values in predictors\n",
    "X = X.dropna()\n",
    "\n",
    "# Encode the target variable 'course_number'\n",
    "course_number_encoder = LabelEncoder()\n",
    "df_merged['encoded_course_level'] = course_number_encoder.fit_transform(df_merged['course_level'])\n",
    "\n",
    "# Predictors\n",
    "X = df_merged[['hs_gpa', 'ERM_SCORE']]\n",
    "\n",
    "# Target variable is'course_number_encoded'\n",
    "y_course_number = df_merged['encoded_course_level']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train_course_number, y_test_course_number = train_test_split(X, y_course_number, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the DecisionTreeClassifier with parameters to control tree complexity\n",
    "clf_course_number = DecisionTreeClassifier(\n",
    "    max_depth=5,               # Limit the depth of the tree\n",
    "    min_samples_split=40,      # Require at least 40 samples to split a node\n",
    "    min_samples_leaf=20,       # Each leaf node must contain at least 20 samples\n",
    "    max_leaf_nodes=15,         # Limit the total number of leaf nodes\n",
    "    random_state=42\n",
    ")\n",
    "# Fit the classifier to the training data\n",
    "clf_course_number.fit(X_train, y_train_course_number)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_course_number = clf_course_number.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate of placements: 0.56\n"
     ]
    }
   ],
   "source": [
    "# Decode the predicted course numbers back to the original encoding\n",
    "predicted_courses = course_number_encoder.inverse_transform(y_pred_course_number)\n",
    "\n",
    "# Add the predicted courses to your test DataFrame\n",
    "X_test.loc[:, 'course_level'] = predicted_courses\n",
    "\n",
    "# Join the original 'grade_category' to the test DataFrame for evaluation\n",
    "X_test = X_test.join(df_merged['grade_category'], how='left')\n",
    "\n",
    "# Evaluate the success by checking the grade_category of the predicted placements\n",
    "successful_placements = X_test[X_test['grade_category'] == 'Successful']\n",
    "success_rate = len(successful_placements) / len(X_test)\n",
    "print(f'Success rate of placements: {success_rate:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"numpy.float64\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Visualize the decision tree\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplot_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf_course_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m          \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcourse_number_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43mfilled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrounded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43mfontsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_export.py:211\u001b[0m, in \u001b[0;36mplot_tree\u001b[1;34m(decision_tree, max_depth, feature_names, class_names, label, filled, impurity, node_ids, proportion, rounded, precision, ax, fontsize)\u001b[0m\n\u001b[0;32m    196\u001b[0m check_is_fitted(decision_tree)\n\u001b[0;32m    198\u001b[0m exporter \u001b[38;5;241m=\u001b[39m _MPLTreeExporter(\n\u001b[0;32m    199\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39mmax_depth,\n\u001b[0;32m    200\u001b[0m     feature_names\u001b[38;5;241m=\u001b[39mfeature_names,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m     fontsize\u001b[38;5;241m=\u001b[39mfontsize,\n\u001b[0;32m    210\u001b[0m )\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexporter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecision_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43max\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_export.py:643\u001b[0m, in \u001b[0;36m_MPLTreeExporter.export\u001b[1;34m(self, decision_tree, ax)\u001b[0m\n\u001b[0;32m    641\u001b[0m ax\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m    642\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_axis_off()\n\u001b[1;32m--> 643\u001b[0m my_tree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecision_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecision_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    644\u001b[0m draw_tree \u001b[38;5;241m=\u001b[39m buchheim(my_tree)\n\u001b[0;32m    646\u001b[0m \u001b[38;5;66;03m# important to make sure we're still\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;66;03m# inside the axis after drawing the box\u001b[39;00m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;66;03m# this makes sense because the width of a box\u001b[39;00m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;66;03m# is about the same as the distance between boxes\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_export.py:619\u001b[0m, in \u001b[0;36m_MPLTreeExporter._make_tree\u001b[1;34m(self, node_id, et, criterion, depth)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_tree\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_id, et, criterion, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;66;03m# traverses _tree.Tree recursively, builds intermediate\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;66;03m# \"_reingold_tilford.Tree\" object\u001b[39;00m\n\u001b[1;32m--> 619\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_to_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43met\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m et\u001b[38;5;241m.\u001b[39mchildren_left[node_id] \u001b[38;5;241m!=\u001b[39m _tree\u001b[38;5;241m.\u001b[39mTREE_LEAF \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m depth \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth\n\u001b[0;32m    622\u001b[0m     ):\n\u001b[0;32m    623\u001b[0m         children \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    624\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_tree(\n\u001b[0;32m    625\u001b[0m                 et\u001b[38;5;241m.\u001b[39mchildren_left[node_id], et, criterion, depth\u001b[38;5;241m=\u001b[39mdepth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    629\u001b[0m             ),\n\u001b[0;32m    630\u001b[0m         ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_export.py:392\u001b[0m, in \u001b[0;36m_BaseTreeExporter.node_to_str\u001b[1;34m(self, tree, node_id, criterion)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m         class_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m    388\u001b[0m             characters[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    389\u001b[0m             np\u001b[38;5;241m.\u001b[39margmax(value),\n\u001b[0;32m    390\u001b[0m             characters[\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m    391\u001b[0m         )\n\u001b[1;32m--> 392\u001b[0m     \u001b[43mnode_string\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclass_name\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# Clean up any trailing newlines\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node_string\u001b[38;5;241m.\u001b[39mendswith(characters[\u001b[38;5;241m4\u001b[39m]):\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"numpy.float64\") to str"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(clf_course_number, \n",
    "          feature_names=X_train.columns, \n",
    "          class_names=course_number_encoder.classes_, \n",
    "          filled=True, rounded=True, \n",
    "          fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the XGBoost model for course number prediction: 0.68\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Encode the target variable\n",
    "course_number_encoder = LabelEncoder()\n",
    "df_merged['course_level_encoded'] = course_number_encoder.fit_transform(df_merged['course_level'])\n",
    "\n",
    "#Prepare the data\n",
    "X = df_merged[['ERM_SCORE', 'hs_gpa']]\n",
    "y = df_merged['course_level_encoded'] \n",
    "\n",
    "# Ensure no NaN values in predictors\n",
    "X = X.dropna()\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Continue with initializing and fitting your XGBoost classifier\n",
    "xgb_model_course_number = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model_course_number.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_course_number = xgb_model_course_number.predict(X_test)\n",
    "\n",
    "# Decode the predicted course numbers back to the original course numbers for interpretability\n",
    "predicted_course_numbers = course_number_encoder.inverse_transform(y_pred_course_number)\n",
    "\n",
    "# Evaluate the predictions\n",
    "accuracy = accuracy_score(y_test, y_pred_course_number)  # This comparison should now be valid\n",
    "print(f'Accuracy of the XGBoost model for course number prediction: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNUSED CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Removing rows with NA in 'hs_gpa' or 'ERM_SCORE' columns before any processing\n",
    "df_merged.dropna(subset=['hs_gpa', 'ERM_SCORE'], inplace=True)\n",
    "\n",
    "# Prepare the incoming_students DataFrame by explicitly creating it or filtering df_merged\n",
    "incoming_students = df_merged.copy()\n",
    "\n",
    "# Define the list of courses, including combinations as tuples\n",
    "included_courses = [\n",
    "    '088', '105Q', '090', '216Q', '132', '121Q', '161Q', '151Q', '165Q', '171Q',\n",
    "    ('005', '105Q'), ('063', '090'), ('021', '121Q')\n",
    "]\n",
    "\n",
    "# Initialize a dictionary to store each course's LabelEncoder and model\n",
    "model_info = {}\n",
    "\n",
    "for course in included_courses:\n",
    "    # Filter the DataFrame for the current course or combination\n",
    "    if isinstance(course, tuple):\n",
    "        df_filtered = df_merged[df_merged['course_number'].isin(course)]\n",
    "    else:\n",
    "        df_filtered = df_merged[df_merged['course_number'] == course]\n",
    "\n",
    "    # Continue only if there are records after filtering\n",
    "    if not df_filtered.empty:\n",
    "        X = df_filtered[['hs_gpa', 'ERM_SCORE']]\n",
    "        y = df_filtered['grade_category']\n",
    "\n",
    "        # Encoding the target variable for the current course\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "        # Train the logistic regression model\n",
    "        log_reg = LogisticRegression(max_iter=1000)\n",
    "        log_reg.fit(X, y_encoded)\n",
    "\n",
    "        # Store the trained model and its label encoder in the dictionary\n",
    "        model_info[course] = {'model': log_reg, 'encoder': label_encoder}\n",
    "\n",
    "# Placeholder DataFrame for storing predictions\n",
    "predictions = pd.DataFrame(index=incoming_students.index)\n",
    "\n",
    "# Iterating over the models to predict outcomes for incoming students\n",
    "for course, info in model_info.items():\n",
    "    model = info['model']\n",
    "    encoder = info['encoder']\n",
    "    \n",
    "    # Predicting with the model\n",
    "    pred_encoded = model.predict(incoming_students[['hs_gpa', 'ERM_SCORE']])\n",
    "\n",
    "    # Inversely transforming encoded predictions into original labels\n",
    "    pred_decoded = encoder.inverse_transform(pred_encoded)\n",
    "\n",
    "    # Storing predictions in the DataFrame under the course name or combination\n",
    "    course_key = '&'.join(course) if isinstance(course, tuple) else course\n",
    "    predictions[course_key] = pred_decoded\n",
    "\n",
    "# Defining a function to determine the highest-level course for which a student is predicted to be successful\n",
    "def determine_highest_level(row):\n",
    "    # Example logic for determining the highest-level course\n",
    "    # You may need to adapt this based on your course hierarchy and success criteria\n",
    "    for course in reversed(included_courses):\n",
    "        course_key = '&'.join(course) if isinstance(course, tuple) else course\n",
    "        if row.get(course_key) == 'Successful':\n",
    "            return course_key\n",
    "    return 'None'\n",
    "\n",
    "# Apply the function to each row in predictions DataFrame\n",
    "predictions['Highest_Level_Course'] = predictions.apply(determine_highest_level, axis=1)\n",
    "\n",
    "output_file = 'Predictions.csv'\n",
    "\n",
    "# Join df_merged with predictions using an appropriate method, e.g., merge, join, concat\n",
    "# Ensure the join keys or indexes align properly between df_merged and predictions\n",
    "# For simplicity, I'll assume df_merged and predictions can be directly concatenated\n",
    "# You may need to adjust based on your actual DataFrame structures\n",
    "df_merged_with_predictions = pd.concat([df_merged, predictions], axis=1)\n",
    "\n",
    "# Save the merged dataframe to a CSV file\n",
    "df_merged_with_predictions.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Predictions saved to '{output_file}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
